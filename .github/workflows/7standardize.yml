#!/usr/bin/env python3
import csv
import os
import pandas as pd
from rapidfuzz import process
import re
import chardet
from pypinyin import lazy_pinyin
from tqdm import tqdm
import time

IPTV_DB_PATH = "./iptv-database"

INPUT_MY = "input/mysource/my_sum.csv"
INPUT_WORKING = "output/working.csv"
OUTPUT_TOTAL = "output/total.csv"
INPUT_CHANNEL = "input/channel.csv"
OUTPUT_CHANNEL = "input/channel.csv"
MANUAL_MAP_PATH = "input/manual_map.csv"

# âœ… ä¿®æ”¹éƒ¨åˆ†ï¼šç»Ÿä¸€ä¸º utf-8-sig çš„è½¬æ¢å‡½æ•°
def ensure_utf8sig(path):
    """æ£€æµ‹æ–‡ä»¶ç¼–ç ï¼Œè‹¥ä¸æ˜¯ utf-8-sigï¼ˆåŒ…æ‹¬ utf-8ï¼‰ï¼Œåˆ™è½¬ä¸º utf-8-sig"""
    if not os.path.exists(path):
        print(f"âš ï¸ æ–‡ä»¶ {path} ä¸å­˜åœ¨ï¼Œè·³è¿‡ç¼–ç æ£€æŸ¥")
        return
    with open(path, 'rb') as f:
        raw = f.read()
    result = chardet.detect(raw)
    enc = (result['encoding'] or 'utf-8').lower()

    # è½¬æ¢æ¡ä»¶ï¼šä¸æ˜¯ utf-8-sigï¼ˆutf_8_sigï¼‰æ—¶
    if enc not in ['utf-8-sig', 'utf_8_sig']:
        try:
            text = raw.decode(enc, errors='ignore')
            with open(path, 'w', encoding='utf-8-sig') as f:
                f.write(text)
            print(f"âœ… æ–‡ä»¶ {path} ä» {enc} è½¬æ¢ä¸º UTF-8-SIG")
        except Exception as e:
            print(f"âŒ è½¬æ¢æ–‡ä»¶ {path} å‡ºé”™: {e}")
    else:
        print(f"âœ… æ–‡ä»¶ {path} å·²æ˜¯ UTF-8-SIGï¼Œæ— éœ€è½¬æ¢")

def convert_all_csv_to_utf8sig(paths):
    for p in paths:
        ensure_utf8sig(p)

# âœ… åç»­è¯»å–ç»Ÿä¸€ä½¿ç”¨ utf-8-sig
def safe_read_csv(path):
    return pd.read_csv(path, encoding="utf-8-sig", on_bad_lines='skip')

# ======================== ä»¥ä¸‹ä¸ºåŸé€»è¾‘ä¿æŒä¸åŠ¨ ========================
def load_name_map():
    name_map = {}
    path = os.path.join(IPTV_DB_PATH, "data", "channels.csv")
    with open(path, encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            std_name = row["name"].strip().title()
            name_map[std_name.lower()] = std_name
            others = row.get("other_names", "")
            for alias in others.split(","):
                alias = alias.strip()
                if alias:
                    name_map[alias.lower()] = std_name
    return name_map

def load_manual_map(path=MANUAL_MAP_PATH):
    manual_map = {}
    if not os.path.exists(path):
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, "w", encoding="utf-8-sig", newline='') as f:
            writer = csv.writer(f)
            writer.writerow(["åŸå§‹åç§°", "æ ‡å‡†åç§°", "æ‹ŸåŒ¹é…é¢‘é“"])
        print(f"âš ï¸ æœªæ‰¾åˆ°äººå·¥æ˜ å°„æ–‡ä»¶ï¼Œå·²æ–°å»ºç©ºæ–‡ä»¶ï¼š{path}")
        return manual_map

    with open(path, encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_name = row.get("åŸå§‹åç§°", "").strip()
            std_name = row.get("æ ‡å‡†åç§°", "").strip().title()
            if raw_name and std_name:
                manual_map[raw_name.lower()] = std_name
    print(f"ğŸ“˜ å·²åŠ è½½äººå·¥æ˜ å°„æ–‡ä»¶ {path}ï¼Œå…± {len(manual_map)} æ¡")
    return manual_map

def clean_channel_name(name):
    if not isinstance(name, str):
        return ""
    name = re.sub(r"[\(\ï¼ˆ][^\)\ï¼‰]*[\)\ï¼‰]", "", name)
    name = re.sub(r"[\[\ã€][^\]\ã€‘]*[\]\ã€‘]", "", name)
    name = re.sub(r"\b(not\s*)?(24/7|7\*24|7x24)\b", "", name, flags=re.I)
    return name.strip()

def normalize_name_for_match(name):
    if not isinstance(name, str):
        return ""
    name = clean_channel_name(name)
    name = re.sub(r"[-\s]", "", name)
    return name.lower()

def standardize_my_sum(my_sum_df):
    my_sum_df['final_name'] = my_sum_df.iloc[:,0].astype(str).str.title()
    my_sum_df['match_info'] = "è‡ªæœ‰æº"
    my_sum_df['original_channel_name'] = my_sum_df.iloc[:,0].astype(str)
    return my_sum_df

def standardize_working(working_df, my_sum_df, name_map, manual_map):
    working_df['original_channel_name'] = working_df.iloc[:, 0].astype(str)
    working_df['clean_name'] = working_df['original_channel_name'].apply(clean_channel_name)
    my_name_dict = dict(zip(my_sum_df.iloc[:,0].apply(normalize_name_for_match), my_sum_df['final_name']))

    total = len(working_df)
    final_names = []
    match_infos = []
    matched_count = 0
    unmatched_count = 0

    print(f"ğŸ”„ å¼€å§‹å¯¹ working.csv å…± {total} æ¡è®°å½•è¿›è¡Œæ ‡å‡†åŒ–åŒ¹é…...")

    start_time = time.time()
    last_print_time = start_time

    for idx, (orig_name, clean_name) in enumerate(tqdm(zip(working_df['original_channel_name'], working_df['clean_name']), total=total), 1):
        orig_name_lower = orig_name.lower()
        clean_name_lower = normalize_name_for_match(clean_name)

        if orig_name_lower in manual_map:
            std_name = manual_map[orig_name_lower]
            match_info = "äººå·¥åŒ¹é…"
            matched_count += 1
        elif clean_name_lower in my_name_dict:
            std_name = my_name_dict[clean_name_lower]
            match_info = "è‡ªæœ‰æºåŒ¹é…"
            matched_count += 1
        else:
            choices = list(name_map.keys())
            match, score, _ = process.extractOne(clean_name_lower, choices)
            if score >= 95:
                std_name = name_map[match]
                match_info = "æ¨¡ç³ŠåŒ¹é…"
                matched_count += 1
            elif score > 0:
                std_name = clean_name.title()
                match_info = f"ä½åŒ¹é…;æ‹ŸåŒ¹é…é¢‘é“:{name_map[match]}"
                unmatched_count += 1
            else:
                std_name = clean_name.title()
                match_info = "æœªåŒ¹é…"
                unmatched_count += 1

        final_names.append(std_name)
        match_infos.append(match_info)

        current_time = time.time()
        if current_time - last_print_time >= 5 or idx == total:
            print(f"å·²å¤„ç† {idx}/{total} æ¡ï¼ŒåŒ¹é… {matched_count} æ¡ï¼ŒæœªåŒ¹é… {unmatched_count} æ¡")
            last_print_time = current_time

    working_df['final_name'] = final_names
    working_df['match_info'] = match_infos
    print("âœ… working.csv æ ‡å‡†åŒ–åŒ¹é…å®Œæˆ")
    return working_df

# ä»¥ä¸‹å‡½æ•°ä¿æŒä¸å˜ï¼ˆçœç•¥é‡å¤éƒ¨åˆ†ï¼‰â€¦â€¦

def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ ‡å‡†åŒ–åŒ¹é…æµç¨‹...")

    # âœ… æ›¿æ¢ä¸º utf-8-sig è‡ªåŠ¨è½¬æ¢é€»è¾‘
    csv_files = [INPUT_MY, INPUT_WORKING, INPUT_CHANNEL, MANUAL_MAP_PATH]
    convert_all_csv_to_utf8sig(csv_files)

    my_sum_df = safe_read_csv(INPUT_MY)
    working_df = safe_read_csv(INPUT_WORKING)

    print(f"è¯»å–æºæ–‡ä»¶ï¼š\n  ğŸ“ {INPUT_MY}\n  ğŸ“ {INPUT_WORKING}")

    name_map = load_name_map()
    manual_map = load_manual_map()
    print(f"âœ… æ•°æ®åº“åŠ è½½å®Œæˆï¼Œæ˜ å°„æ€»æ•°ï¼š{len(name_map)}ï¼Œäººå·¥æ˜ å°„æ¡æ•°ï¼š{len(manual_map)}")

    # å…¶ä½™é€»è¾‘ä¿æŒä¸å˜â€¦â€¦