import aiohttp
import asyncio
import csv
import os
import time
from aiohttp import ClientTimeout

# ==============================
# é…ç½®åŒº
# ==============================
INPUT_FILE = "input/network/network_sources.csv"
WORKING_CSV = "output/working.csv"
WORKING_M3U = "output/working.m3u"
SKIPPED_LOG = "output/skipped.log"
FAILED_LOG = "output/failed.log"

MAX_CONCURRENT = 50  # å¹¶å‘æ£€æµ‹æ•°é‡
TIMEOUT_SECONDS = 8  # æ£€æµ‹è¶…æ—¶ï¼ˆç§’ï¼‰

# âœ… ç™½åå•ï¼šä¼˜å…ˆä¿ç•™
WHITELIST_PATTERNS = [
    "cctv", "å¤®è§†", "å«è§†", "å‡¤å‡°", "bloomberg", "bbc", "cnn",
    "discovery", "hbo", "espn", "nba", "fox", "abc"
]

# ğŸš« å±è”½ä½æ¸…æ™°åº¦å…³é”®è¯ï¼ˆåŒ…å«720pï¼‰
LOW_RES_KEYWORDS = [
    "vga", "480p", "576p", "360p", "240p", "144p", "sd", "720p"
]

# ğŸš« é»‘åå•å…³é”®è¯ï¼ˆæµ‹è¯•æºã€éŸ³é¢‘ã€æˆäººå†…å®¹ç­‰ï¼‰
BLOCK_KEYWORDS = [
    "test", "offline", "cam", "porn", "xxx", "sex",
    "radio", "audio", "music", "vr", "demo"
]

# ==============================
# æ—¥å¿—å‡½æ•°
# ==============================
def log_skip(reason, title, url):
    with open(SKIPPED_LOG, "a", encoding="utf-8") as f:
        f.write(f"{reason},{title},{url}\n")

def log_fail(reason, title, url):
    with open(FAILED_LOG, "a", encoding="utf-8") as f:
        f.write(f"{reason},{title},{url}\n")

# ==============================
# æ ¸å¿ƒè¿‡æ»¤é€»è¾‘
# ==============================
def is_allowed(title, url):
    text = f"{title} {url}".lower()
    # âœ… ç™½åå•ä¼˜å…ˆä¿ç•™
    if any(w in text for w in WHITELIST_PATTERNS):
        return True
    # ğŸš« æ’é™¤ä½æ¸…æ™°åº¦
    if any(kw in text for kw in LOW_RES_KEYWORDS):
        log_skip("LOW_RES_SKIP", title, url)
        return False
    # ğŸš« æ’é™¤é»‘åå•å…³é”®è¯
    if any(kw in text for kw in BLOCK_KEYWORDS):
        log_skip("BLOCK_KEYWORD", title, url)
        return False
    return True

# ==============================
# å¼‚æ­¥æ£€æµ‹å‡½æ•°
# ==============================
async def check_url(session, title, url, logo):
    start = time.time()
    try:
        async with session.get(url, timeout=ClientTimeout(total=TIMEOUT_SECONDS)) as resp:
            if resp.status == 200:
                elapsed = time.time() - start
                print(f"âœ… {title} æ­£å¸¸ ({elapsed:.2f}s)")
                return True, elapsed, url, title, logo
            else:
                log_fail(f"HTTP_{resp.status}", title, url)
    except Exception as e:
        log_fail(str(e), title, url)
    return False, None, url, title, logo

# ==============================
# å†™å…¥ç»“æœæ–‡ä»¶
# ==============================
def write_working_csv(all_working):
    with open(WORKING_CSV, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        # âœ… æŒ‰è¦æ±‚ä¿®æ”¹è¡¨å¤´
        writer.writerow(["é¢‘é“å", "åœ°å€", "æ¥æº", "æ£€æµ‹æ—¶é—´", "å›¾æ ‡", "åˆ†ç»„"])
        for ok, elapsed, url, name, logo in all_working:
            if ok:
                writer.writerow([
                    name,            # é¢‘é“å
                    url,             # åœ°å€
                    "ç½‘ç»œæº",         # æ¥æº
                    f"{elapsed:.2f}",# æ£€æµ‹æ—¶é—´ï¼ˆç§’ï¼‰
                    logo or "",      # å›¾æ ‡
                    ""               # åˆ†ç»„ï¼ˆç•™ç©ºï¼‰
                ])
    print(f"ğŸ“ ç”Ÿæˆ working.csv: {WORKING_CSV}")

def write_working_m3u(all_working):
    with open(WORKING_M3U, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for ok, elapsed, url, name, logo in all_working:
            if ok:
                logo_part = f'tvg-logo="{logo}" ' if logo else ""
                f.write(f'#EXTINF:-1 {logo_part},{name}\n{url}\n')
    print(f"ğŸ“º ç”Ÿæˆ working.m3u: {WORKING_M3U}")

# ==============================
# ä¸»æµç¨‹
# ==============================
async def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ï¼š{INPUT_FILE}")
        return

    pairs = []
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) < 2:
                continue
            title, url = row[0].strip(), row[1].strip()
            logo = row[2].strip() if len(row) > 2 else ""
            pairs.append((title, url, logo))

    print(f"ğŸ“– è¯»å–æºå…± {len(pairs)} æ¡")

    # âœ… è¿‡æ»¤ä½æ¸…æ™°åº¦ä¸é»‘åå•
    filtered_pairs = [p for p in pairs if is_allowed(p[0], p[1])]
    print(f"ğŸš« è·³è¿‡æº: {len(pairs) - len(filtered_pairs)} æ¡ï¼ˆä½æ¸…æ™°åº¦æˆ–é»‘åå•ï¼‰")
    print(f"ğŸ§ª å¾…æ£€æµ‹æº: {len(filtered_pairs)} æ¡")

    # å¼‚æ­¥æ£€æµ‹
    connector = aiohttp.TCPConnector(limit=MAX_CONCURRENT)
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = [check_url(session, name, url, logo) for name, url, logo in filtered_pairs]
        results = await asyncio.gather(*tasks)

    # å†™å…¥ç»“æœæ–‡ä»¶
    write_working_csv(results)
    write_working_m3u(results)
    print("âœ… æ£€æµ‹å®Œæˆ")

# ==============================
# è¿è¡Œå…¥å£
# ==============================
if __name__ == "__main__":
    asyncio.run(main())
