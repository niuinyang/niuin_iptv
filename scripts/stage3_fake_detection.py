import aiohttp
import asyncio
import csv
import os
import time
from PIL import Image
import imagehash
import tempfile

INPUT_FILE = "output/middle/stage2b_verified.csv"
OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

OUTPUT_CSV = os.path.join(OUTPUT_DIR, "stage3_final_checked.csv")
OUTPUT_M3U = os.path.join(OUTPUT_DIR, "stage3_final_checked.m3u")

MAX_CONCURRENCY = 40
CHECK_TIMES = 2
INTERVAL_BETWEEN_CHECKS = 1.5
TIMEOUT = 8
FAKE_HASH_DIFF_THRESHOLD = 5

sem = asyncio.Semaphore(MAX_CONCURRENCY)

def log(msg):
    print(msg)

async def get_start_frame_hash(url):
    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=True) as tmpfile:
        tmp_path = tmpfile.name
        cmd = [
            "ffmpeg",
            "-timeout", "5000000",
            "-i", url,
            "-frames:v", "1",
            "-q:v", "2",
            "-y",
            tmp_path
        ]
        try:
            proc = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.DEVNULL,
                stderr=asyncio.subprocess.DEVNULL,
            )
            try:
                await asyncio.wait_for(proc.communicate(), timeout=15)
            except asyncio.TimeoutError:
                proc.kill()
                await proc.communicate()
                return None

            if os.path.exists(tmp_path) and os.path.getsize(tmp_path) > 0:
                img = Image.open(tmp_path)
                phash = imagehash.phash(img)
                return phash
        except Exception:
            return None
    return None

def is_fake_source(hashes):
    for i in range(len(hashes)):
        for j in range(i+1, len(hashes)):
            if hashes[i] - hashes[j] <= FAKE_HASH_DIFF_THRESHOLD:
                return True
    return False

async def ffprobe_check(url):
    try:
        cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "v:0",
            "-show_entries", "stream=width,height,codec_name",
            "-of", "csv=p=0", url
        ]
        proc = await asyncio.create_subprocess_exec(
            *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
        )
        stdout, _ = await proc.communicate()
        if stdout:
            lines = stdout.decode().strip().splitlines()
            return lines[0] if lines else ""
        return ""
    except Exception:
        return ""

async def check_stream_multiple(session, row):
    async with sem:
        name, url, source, logo = row
        phashes = []
        for i in range(CHECK_TIMES):
            phash = await get_start_frame_hash(url)
            if phash is None:
                log(f"âš ï¸ {name} ç¬¬{i+1}æ¬¡æ£€æµ‹æ— æ³•è·å–èµ·å§‹å¸§å“ˆå¸Œ")
                return None
            phashes.append(phash)
            if i < CHECK_TIMES - 1:
                await asyncio.sleep(INTERVAL_BETWEEN_CHECKS)

        if is_fake_source(phashes):
            log(f"âŒ å‡æºæ’é™¤: {name}")
            return None

        ff_info = await ffprobe_check(url)
        detect_time = "N/A"

        log(f"âœ… æœ‰æ•ˆæº: {name}")
        return [name, url, source, logo, detect_time, "ç½‘ç»œæº", ff_info or ""]

async def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        return

    with open(INPUT_FILE, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        required_cols = ["é¢‘é“å", "åœ°å€", "æ¥æº", "å›¾æ ‡"]
        for col in required_cols:
            if col not in reader.fieldnames:
                raise ValueError(f"CSV æ–‡ä»¶ç¼ºå°‘ required åˆ—: '{col}'")
        rows = [[r["é¢‘é“å"], r["åœ°å€"], r["æ¥æº"], r["å›¾æ ‡"]] for r in reader]

    total = len(rows)
    print(f"ğŸ“¦ æ€»æºæ•°: {total} æ¡ï¼Œå¼€å§‹ç¬¬3é˜¶æ®µå¤šæ¬¡æ£€æµ‹...")

    valid_results = []
    start_time = time.time()
    pbar = tqdm(total=total, desc="æ£€æµ‹è¿›åº¦", unit="æ¡")

    async with aiohttp.ClientSession() as session:
        for idx, row in enumerate(rows):
            result = await check_stream_multiple(session, row)
            if result:
                valid_results.append(result)
            pbar.update(1)

            if (idx + 1) % 100 == 0 or (idx + 1) == total:
                elapsed = time.time() - start_time
                speed = (idx + 1) / elapsed if elapsed > 0 else 0
                eta = (total - idx - 1) / speed if speed > 0 else 0
                print(f"è¿›åº¦: {idx + 1}/{total} | æœ‰æ•ˆ: {len(valid_results)} | é€Ÿç‡: {speed:.2f}æ¡/s | é¢„è®¡å‰©ä½™: {eta/60:.1f} åˆ†é’Ÿ")

    pbar.close()

    with open(OUTPUT_CSV, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["é¢‘é“å", "åœ°å€", "æ¥æº", "å›¾æ ‡", "æ£€æµ‹æ—¶é—´(å»¶è¿Ÿ)", "åˆ†ç»„", "è§†é¢‘ä¿¡æ¯"])
        writer.writerows(valid_results)

    with open(OUTPUT_M3U, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for name, url, source, logo, t, grp, info in valid_results:
            f.write(f'#EXTINF:-1 tvg-logo="{logo}",{name}\n{url}\n')

    total_time = time.time() - start_time
    print(f"\nâœ… ç¬¬3é˜¶æ®µå®Œæˆï¼Œæœ‰æ•ˆæº: {len(valid_results)} æ¡")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {OUTPUT_CSV} å’Œ {OUTPUT_M3U}")
    print(f"ğŸ•’ æ€»è€—æ—¶: {total_time:.2f} ç§’")

if __name__ == "__main__":
    import tqdm
    asyncio.run(main())
