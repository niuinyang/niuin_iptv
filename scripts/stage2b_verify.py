import csv
import subprocess
import concurrent.futures
from tqdm import tqdm
import os

INPUT_CSV = "output/middle/stage2a_valid.csv"
OUTPUT_CSV = "output/middle/stage2b_verified.csv"
SNAPSHOT_INTERVAL = 500
MAX_WORKERS = 20  # å¹¶å‘çº¿ç¨‹æ•°ï¼Œè§†æœåŠ¡å™¨è°ƒæ•´

def run_ffprobe(url):
    """è°ƒç”¨ ffprobe éªŒè¯æµï¼Œè¿”å›ç»“æœå­—ç¬¦ä¸²æˆ–é”™è¯¯ä¿¡æ¯"""
    try:
        # ffprobe å‘½ä»¤ï¼Œ-v quiet é™é»˜ï¼Œ-show_format æ˜¾ç¤ºæ ¼å¼ä¿¡æ¯
        # timeout 10ç§’é˜²æ­¢å¡ä½
        cmd = [
            "ffprobe", "-v", "quiet",
            "-print_format", "json",
            "-show_format",
            "-show_streams",
            url
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            return "âœ…æœ‰æ•ˆ"
        else:
            return f"âŒé”™è¯¯: {result.stderr.strip()[:100]}"
    except subprocess.TimeoutExpired:
        return "âŒè¶…æ—¶"
    except Exception as e:
        return f"âŒå¼‚å¸¸: {str(e)}"

def process_row(row):
    url = row['åœ°å€']
    ffprobe_result = run_ffprobe(url)
    return {**row, 'ffprobeç»“æœ': ffprobe_result}

def save_snapshot(data, filename):
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=data[0].keys())
        writer.writeheader()
        writer.writerows(data)

def main():
    if not os.path.exists("output/middle"):
        os.makedirs("output/middle")

    # è¯»å–å¾…æ£€æµ‹æ•°æ®
    with open(INPUT_CSV, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    results = []
    start_index = 0

    # æ¢å¤æ£€æµ‹ï¼Œè‹¥å¿«ç…§æ–‡ä»¶å­˜åœ¨åˆ™åŠ è½½ç»§ç»­
    if os.path.exists(OUTPUT_CSV):
        with open(OUTPUT_CSV, newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            results = list(reader)
        start_index = len(results)
        print(f"æ¢å¤æ£€æµ‹ï¼Œä»ç¬¬ {start_index} æ¡å¼€å§‹ï¼Œå…± {len(rows)} æ¡")

    total = len(rows)
    print(f"ğŸš€ å¼€å§‹ç¬¬2é˜¶æ®µæ£€æµ‹ï¼ˆFFprobeéªŒè¯ï¼‰")
    print(f"ğŸ“¦ å½“å‰å¾…æ£€æµ‹æºæ•°ï¼š{total - start_index}")

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤å‰©ä½™ä»»åŠ¡
        future_to_index = {
            executor.submit(process_row, rows[i]): i
            for i in range(start_index, total)
        }

        # ä½¿ç”¨ tqdm è¿›åº¦æ¡ç›‘æ§
        for future in tqdm(concurrent.futures.as_completed(future_to_index), total=total - start_index, desc="æ£€æµ‹è¿›åº¦"):
            idx = future_to_index[future]
            try:
                res = future.result()
                results.append(res)
            except Exception as e:
                # å‡ºé”™æ—¶è¿”å›é”™è¯¯ä¿¡æ¯
                row = rows[idx]
                row['ffprobeç»“æœ'] = f"âŒå¼‚å¸¸: {str(e)}"
                results.append(row)

            # æ¯500æ¡ä¿å­˜å¿«ç…§ï¼Œé˜²æ­¢æ„å¤–ä¸­æ–­ä¸¢å¤±è¿›åº¦
            if len(results) % SNAPSHOT_INTERVAL == 0:
                save_snapshot(results, OUTPUT_CSV)
                print(f"ğŸ’¾ å·²ä¿å­˜å¿«ç…§ï¼š{len(results)}/{total}")

    # å…¨éƒ¨å®Œæˆåä¿å­˜æœ€ç»ˆç»“æœ
    save_snapshot(results, OUTPUT_CSV)
    print(f"âœ… é˜¶æ®µ2å®Œæˆï¼Œç»“æœè¾“å‡ºï¼š{OUTPUT_CSV}")

if __name__ == "__main__":
    main()
