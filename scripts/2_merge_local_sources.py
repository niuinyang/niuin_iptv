#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç¼–ç ç‰ˆ IPTV åˆå¹¶è„šæœ¬
æ”¯æŒå¤šè¯­è¨€æ–‡ä»¶ï¼ˆä¸­æ–‡ / è‹±æ–‡ / ä¿„è¯­ / è¥¿è‘¡è¯­ï¼‰
è¾“å‡ºæ–‡ä»¶ UTF-8 æ—  BOMï¼Œå…¼å®¹ Excel / GitHub / Windows / macOS
"""

import os
import re
import csv
import chardet
import platform

# è¾“å…¥ç›®å½•ï¼Œåˆ†åˆ«æ˜¯ç½‘ç»œæºå’Œæˆ‘çš„æºç›®å½•
networksource_dir = "input/download/network"
mysource_dir = "input/download/my"

# è¾“å‡ºç›®å½•åŠæ—¥å¿—ç›®å½•é…ç½®
OUTPUT_DIR = "output"
LOG_DIR = os.path.join(OUTPUT_DIR, "log")
MERGE_DIR = "output/middle/merge"
LOG_MERGE_DIR = os.path.join(LOG_DIR, "merge")

# åˆ›å»ºè¾“å‡ºå’Œæ—¥å¿—ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(MERGE_DIR, exist_ok=True)
os.makedirs(LOG_MERGE_DIR, exist_ok=True)

# è¾“å‡ºåˆå¹¶åæ–‡ä»¶çš„è·¯å¾„é…ç½®
NETWORK_M3U = os.path.join(MERGE_DIR, "networksource_total.m3u")
NETWORK_CSV = os.path.join(MERGE_DIR, "networksource_total.csv")
NETWORK_LOG = os.path.join(LOG_MERGE_DIR, "networksource_skipped.log")

MYSOURCE_M3U = os.path.join(MERGE_DIR, "mysource_total.m3u")
MYSOURCE_CSV = os.path.join(MERGE_DIR, "mysource_total.csv")
MYSOURCE_LOG = os.path.join(LOG_MERGE_DIR, "mysource_skipped.log")

# æ¥æºæ–‡ä»¶ååˆ°ä¸­æ–‡æè¿°çš„æ˜ å°„ï¼Œæ–¹ä¾¿åŒºåˆ†ä¸åŒæ¥æº
SOURCE_MAPPING = {
    "1sddxzb.m3u": "æµå—ç”µä¿¡ç»„æ’­",
    "2sddxdb.m3u": "æµå—ç”µä¿¡å•æ’­",
    "3jnltzb.m3u": "æµå—è”é€šç»„æ’­",
    "4sdqdlt.m3u": "é’å²›è”é€šå•æ’­",
    "5sdyd_ipv6.m3u": "å±±ä¸œç§»åŠ¨å•æ’­",
    "6shyd_ipv6.m3u": "ä¸Šæµ·ç§»åŠ¨å•æ’­",
}

def safe_open(file_path):
    """
    è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç å¹¶è¯»å–å†…å®¹ä¸ºè¡Œåˆ—è¡¨ï¼Œå»é™¤éšè—å­—ç¬¦ã€‚
    å…¼å®¹å„ç§ç¼–ç æ ¼å¼ï¼Œé¿å…å› ç¼–ç é”™è¯¯å¯¼è‡´è¯»å–å¤±è´¥ã€‚
    """
    with open(file_path, 'rb') as f:
        raw = f.read()
        enc = chardet.detect(raw)['encoding'] or 'utf-8'
    try:
        text = raw.decode(enc, errors='ignore')
    except Exception:
        text = raw.decode('utf-8', errors='ignore')
    text = text.replace('\x00', '')  # æ¸…ç†ç©ºå­—ç¬¦
    return text.splitlines()

def read_m3u_file(file_path: str):
    """
    è¯»å– M3U æ–‡ä»¶ï¼Œè§£æé¢‘é“ä¿¡æ¯ã€‚
    æ”¯æŒè§£æEXTINFè¡Œï¼Œæå–é¢‘é“åã€æ’­æ”¾åœ°å€ã€å›¾æ ‡URLã€‚
    è¿”å›é¢‘é“å­—å…¸åˆ—è¡¨ã€‚
    """
    channels = []
    try:
        lines = safe_open(file_path)
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            if line.startswith("#EXTINF:"):
                info_line = line
                url_line = lines[i + 1].strip() if i + 1 < len(lines) else ""

                if info_line.startswith("#EXTINF:-1 "):
                    content = info_line[len("#EXTINF:-1 "):]
                else:
                    content = info_line[len("#EXTINF:"):]

                attributes = re.findall(r'\w+="[^"]*"', content)
                for attr in attributes:
                    content = content.replace(attr, '')

                if ',' in content:
                    display_name = content.split(',')[-1].strip()
                else:
                    display_name = content.strip()

                logo_match = re.search(r'tvg-logo="([^"]+)"', info_line)
                tvg_logo_url = logo_match.group(1).strip() if logo_match else ""

                channels.append({
                    "display_name": display_name,
                    "url": url_line,
                    "logo": tvg_logo_url
                })
                i += 2
            else:
                i += 1

        print(f"ğŸ“¡ å·²åŠ è½½ {os.path.basename(file_path)}: {len(channels)} æ¡é¢‘é“")
        return channels

    except Exception as e:
        print(f"âš ï¸ è¯»å– {file_path} å¤±è´¥: {e}")
        return []

def read_txt_multi_section_csv(file_path: str):
    """
    è¯»å–TXTæˆ–CSVæ ¼å¼æ–‡ä»¶ï¼ˆå¤šæ®µæ ‡é¢˜æ ¼å¼ï¼‰ï¼Œ
    è¿‡æ»¤æ— æ•ˆè¡Œå’Œæ³¨é‡Šï¼Œæå–é¢‘é“åå’Œæ’­æ”¾åœ°å€ã€‚
    è¿”å›é¢‘é“å­—å…¸åˆ—è¡¨ã€‚
    """
    channels = []
    try:
        lines = safe_open(file_path)
        for line in lines:
            line = line.strip()
            if not line or "#genre#" in line:
                continue
            parts = line.split(",", 1)
            if len(parts) != 2:
                continue
            display_name, url = parts[0].strip(), parts[1].strip()
            if not (url.startswith("http://") or url.startswith("https://") or url.startswith("rtsp://")):
                continue
            channels.append({
                "display_name": display_name,
                "url": url,
                "logo": ""
            })
        print(f"ğŸ“¡ å·²åŠ è½½ {os.path.basename(file_path)}: {len(channels)} æ¡é¢‘é“")
        return channels
    except Exception as e:
        print(f"âš ï¸ è¯»å– {file_path} å¤±è´¥: {e}")
        return []

def merge_all_sources(source_dir):
    """
    éå†æŒ‡å®šç›®å½•ï¼Œè¯»å–æ‰€æœ‰M3Uå’ŒTXTæ–‡ä»¶ï¼Œåˆå¹¶é¢‘é“åˆ—è¡¨ã€‚
    é’ˆå¯¹ç‰¹å®šæ–‡ä»¶è¿›è¡Œåœ°å€æ›¿æ¢å¤„ç†ã€‚
    è¿”å›åˆå¹¶åçš„é¢‘é“åˆ—è¡¨ã€‚
    """
    all_channels = []
    if not os.path.exists(source_dir):
        print(f"âš ï¸ æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
        return []

    print(f"ğŸ“‚ æ‰«æç›®å½•: {source_dir}")
    for file in os.listdir(source_dir):
        file_path = os.path.join(source_dir, file)
        if file.endswith(".m3u"):
            chs = read_m3u_file(file_path)
            if file == "1sddxzb.m3u":
                for ch in chs:
                    ch["url"] = ch["url"].replace("192.168.50.1:20231", "192.168.31.2:4022")
        elif file.endswith(".txt"):
            chs = read_txt_multi_section_csv(file_path)
        else:
            continue
        for ch in chs:
            ch["source_file"] = file
        all_channels.extend(chs)

    print(f"\nğŸ“Š åˆå¹¶æ‰€æœ‰é¢‘é“ï¼Œå…± {len(all_channels)} æ¡")
    return all_channels

def write_output_files(channels, output_m3u, output_csv, skipped_log):
    """
    å°†åˆå¹¶åçš„é¢‘é“åˆ—è¡¨å†™å…¥M3Uå’ŒCSVæ–‡ä»¶ã€‚
    åŒæ—¶ç”Ÿæˆè·³è¿‡çš„é¢‘é“æ—¥å¿—ï¼Œè¿‡æ»¤æ— æ•ˆæˆ–é‡å¤URLã€‚
    è¾“å‡ºå…¨éƒ¨æ–‡ä»¶å‡ä¸ºUTF-8æ— BOMç¼–ç ã€‚
    """
    seen_urls = set()
    valid_channels = []
    skipped_channels = []

    for ch in channels:
        url = ch["url"]
        if not (url.startswith("http://") or url.startswith("https://") or url.startswith("rtsp://")):
            skipped_channels.append({
                "display_name": ch["display_name"],
                "url": url,
                "reason": "æ— æ•ˆURLï¼ˆé http/https/rtsp å¼€å¤´ï¼‰"
            })
            continue
        if url in seen_urls:
            skipped_channels.append({
                "display_name": ch["display_name"],
                "url": url,
                "reason": "é‡å¤URL"
            })
            continue
        seen_urls.add(url)

        source_file = ch.get("source_file", "")
        source_desc = SOURCE_MAPPING.get(source_file, "ç½‘ç»œæº")

        valid_channels.append({
            "display_name": ch["display_name"],
            "url": url,
            "logo": ch.get("logo", ""),
            "source": source_desc,
        })

    print(f"\nâœ… æœ‰æ•ˆé¢‘é“: {len(valid_channels)} æ¡ï¼ˆå»é‡åï¼‰")
    print(f"ğŸš« è·³è¿‡æ— æ•ˆæˆ–é‡å¤: {len(skipped_channels)} æ¡")

    with open(output_m3u, "w", encoding="utf-8", newline="\n") as f:
        f.write("#EXTM3U\n")
        for ch in valid_channels:
            f.write(f'#EXTINF:-1,{ch["display_name"]}\n{ch["url"]}\n')

    with open(output_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["é¢‘é“å", "åœ°å€", "æ¥æº", "å›¾æ ‡"])
        for ch in valid_channels:
            writer.writerow([ch["display_name"], ch["url"], ch["source"], ch.get("logo", "")])

    with open(skipped_log, "w", encoding="utf-8") as f:
        f.write("é¢‘é“å,åœ°å€,è·³è¿‡åŸå› \n")
        for ch in skipped_channels:
            f.write(f"{ch['display_name']},{ch['url']},{ch['reason']}\n")

    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ï¼š{output_m3u} å’Œ {output_csv}")
    print(f"ğŸ“ è·³è¿‡æ—¥å¿—ï¼š{skipped_log}")

if __name__ == "__main__":
    print(f"ğŸ”§ å½“å‰ç³»ç»Ÿ: {platform.system()}ï¼Œè¾“å‡ºç»Ÿä¸€ä¸º UTF-8 æ—  BOM")

    channels = merge_all_sources(networksource_dir)
    if channels:
        write_output_files(
            channels,
            output_m3u=NETWORK_M3U,
            output_csv=NETWORK_CSV,
            skipped_log=NETWORK_LOG
        )
    else:
        print("âš ï¸ æ²¡æœ‰è¯»å–åˆ°ä»»ä½•é¢‘é“")

    channels_my = merge_all_sources(mysource_dir)
    if channels_my:
        write_output_files(
            channels_my,
            output_m3u=MYSOURCE_M3U,
            output_csv=MYSOURCE_CSV,
            skipped_log=MYSOURCE_LOG
        )
    else:
        print(f"âš ï¸ æ²¡æœ‰è¯»å–åˆ°ä»»ä½•é¢‘é“ï¼š{mysource_dir}")
