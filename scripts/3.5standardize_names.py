#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
standardize_channels.py
ä½¿ç”¨ iptv-org/database è‡ªåŠ¨æ ‡å‡†åŒ–é¢‘é“åï¼Œè‡ªåŠ¨é€‚é…æ–‡ä»¶ç¼–ç ï¼Œç”Ÿæˆæ€»è¡¨å’Œé¢‘é“åˆ†ç»„æ˜ å°„ã€‚
"""

import os, csv, pandas as pd, requests
from rapidfuzz import process

IPTV_DB_URL = "https://raw.githubusercontent.com/iptv-org/database/master/data/channels.csv"
IPTV_DB_FILE = "channels.csv"
OUTPUT_DIR = "output"
INPUT_CHANNEL_CSV = "input/channel.csv"
THRESHOLD = 85

def update_database():
    print("ğŸ”½ æ­£åœ¨ä¸‹è½½æœ€æ–° channels.csv ...")
    try:
        r = requests.get(IPTV_DB_URL, timeout=30)
        r.raise_for_status()
        with open(IPTV_DB_FILE, "wb") as f:
            f.write(r.content)
        print("âœ… æ•°æ®åº“ä¸‹è½½å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ ä¸‹è½½å¤±è´¥: {e}")
        if not os.path.exists(IPTV_DB_FILE):
            raise SystemExit("âŒ æ²¡æœ‰å¯ç”¨çš„é¢‘é“æ•°æ®åº“")

def load_name_map():
    name_map = {}
    with open(IPTV_DB_FILE, encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            std = row["name"].strip()
            name_map[std.lower()] = std
            aliases = row.get("aliases", "") or row.get("other_names", "")
            for alias in aliases.replace("|", ",").split(","):
                alias = alias.strip()
                if alias:
                    name_map[alias.lower()] = std
    print(f"ğŸ“š å·²åŠ è½½ {len(name_map)} ä¸ªåç§°æ˜ å°„")
    return name_map

def read_csv_auto(path, encodings=None):
    """
    å°è¯•å¤šç§ç¼–ç è¯»å– CSV æ–‡ä»¶ï¼Œè¿”å› DataFrameã€‚
    é»˜è®¤å°è¯• ['utf-8-sig', 'utf-8', 'gbk', 'latin1']ã€‚
    """
    if encodings is None:
        encodings = ['utf-8-sig', 'utf-8', 'gbk', 'latin1']

    for enc in encodings:
        try:
            df = pd.read_csv(path, encoding=enc)
            print(f"âœ… ä½¿ç”¨ç¼–ç  {enc} è¯»å–æ–‡ä»¶æˆåŠŸ: {path}")
            return df
        except UnicodeDecodeError:
            print(f"âš ï¸ ç¼–ç  {enc} è¯»å–å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
    # å…¨å¤±è´¥æ‰æŠ›å¼‚å¸¸
    raise UnicodeDecodeError(f"æ— æ³•ç”¨å¤‡é€‰ç¼–ç è¯»å–æ–‡ä»¶: {path}")

def match_name(name, name_map):
    n = name.strip()
    if not n:
        return n, "ç©ºå"
    key = n.lower()
    if key in name_map:
        return name_map[key], "ç²¾ç¡®åŒ¹é…"
    match, score, _ = process.extractOne(key, list(name_map.keys()))
    if score >= THRESHOLD:
        return name_map[match], f"æ¨¡ç³ŠåŒ¹é…({score:.0f})"
    return n, "æœªåŒ¹é…"

def standardize_csv(path, name_map):
    print(f"ğŸ“‚ æ­£åœ¨å¤„ç†: {path}")
    df = read_csv_auto(path)
    unmatched = set()
    std_names, statuses = [], []

    for name in df.iloc[:, 0].astype(str):
        std, status = match_name(name, name_map)
        std_names.append(std)
        statuses.append(status)
        if status == "æœªåŒ¹é…":
            unmatched.add(name)

    df.insert(0, "æ ‡å‡†é¢‘é“å", std_names)
    df.insert(1, "åŒ¹é…çŠ¶æ€", statuses)

    out_path = path.replace(".csv", "_standardized.csv")
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ç”Ÿæˆ: {out_path}")

    return df, unmatched

def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    update_database()
    name_map = load_name_map()

    input_files = [
        "input/mysource/my_sum.csv",
        "output/working.csv"
    ]

    all_unmatched = set()
    dfs = []

    for f in input_files:
        if os.path.exists(f):
            df, unmatched = standardize_csv(f, name_map)
            all_unmatched |= unmatched
            dfs.append(df)
        else:
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {f}")

    if dfs:
        total_df = pd.concat(dfs, ignore_index=True)
        total_csv_path = os.path.join(OUTPUT_DIR, "total.csv")
        total_df.to_csv(total_csv_path, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²ç”Ÿæˆæ€»è¡¨: {total_csv_path}")

        if "åˆ†ç»„" in total_df.columns:
            channel_df = total_df[["æ ‡å‡†é¢‘é“å", "åˆ†ç»„"]].drop_duplicates()
            os.makedirs(os.path.dirname(INPUT_CHANNEL_CSV), exist_ok=True)
            channel_df.to_csv(INPUT_CHANNEL_CSV, index=False, encoding="utf-8-sig")
            print(f"âœ… å·²ç”Ÿæˆé¢‘é“åˆ†ç»„æ˜ å°„: {INPUT_CHANNEL_CSV}")
        else:
            print("âš ï¸ æ€»è¡¨ä¸­æœªæ‰¾åˆ°â€œåˆ†ç»„â€åˆ—ï¼Œæ— æ³•ç”Ÿæˆé¢‘é“åˆ†ç»„æ˜ å°„æ–‡ä»¶")

    if all_unmatched:
        report_path = os.path.join(OUTPUT_DIR, "unmatched_channels.txt")
        with open(report_path, "w", encoding="utf-8") as f:
            for ch in sorted(all_unmatched):
                f.write(ch + "\n")
        print(f"âš ï¸ æœªåŒ¹é…é¢‘é“ {len(all_unmatched)} ä¸ªï¼Œå·²ä¿å­˜è‡³ {report_path}")
    else:
        print("ğŸ‰ æ‰€æœ‰é¢‘é“å‡å·²åŒ¹é…")

if __name__ == "__main__":
    main()