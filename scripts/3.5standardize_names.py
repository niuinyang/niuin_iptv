import os
import re
import pandas as pd
from rapidfuzz import process

# ==============================
# é…ç½®åŒº
# ==============================
IPTV_DB_PATH = "./iptv-database"
INPUT_MY = "input/mysource/my_sum.csv"
INPUT_WORKING = "output/working.csv"
INPUT_NETWORK = "output/sum_network.csv"
OUTPUT_TOTAL = "output/total.csv"
OUTPUT_CHANNEL = "input/channel.csv"

# ==============================
# è‡ªåŠ¨æ£€æµ‹ä¸è½¬ç 
# ==============================
def safe_read_csv(path):
    """å°è¯•å¤šç§ç¼–ç è¯»å– CSV æ–‡ä»¶ï¼Œè‹¥é UTF-8 åˆ™è‡ªåŠ¨è½¬ç ä¿å­˜"""
    encodings_to_try = ["utf-8", "utf-8-sig", "gbk", "big5", "latin-1"]
    for enc in encodings_to_try:
        try:
            df = pd.read_csv(path, encoding=enc)
            if enc not in ["utf-8", "utf-8-sig"]:
                print(f"ğŸ”„ æ£€æµ‹åˆ° {os.path.basename(path)} ç¼–ç ä¸º {enc}ï¼Œæ­£åœ¨è½¬æ¢ä¸º UTF-8...")
                df.to_csv(path, index=False, encoding="utf-8-sig")
                print(f"âœ… å·²è½¬ç å¹¶è¦†ç›–ä¿å­˜ä¸º UTF-8: {path}")
            return df
        except UnicodeDecodeError:
            continue
        except pd.errors.ParserError:
            continue
    raise ValueError(f"âŒ æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç : {path}")

# ==============================
# åŠ è½½ç½‘ç»œæ•°æ®åº“
# ==============================
def load_name_map():
    """åŠ è½½ iptv-org æ•°æ®åº“é¢‘é“ååŠåˆ«åæ˜ å°„"""
    name_map = {}
    path = os.path.join(IPTV_DB_PATH, "data", "channels.csv")
    if not os.path.exists(path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶: {path}")
    with open(path, encoding="utf-8") as f:
        for row in pd.read_csv(f).to_dict(orient="records"):
            std_name = row.get("name", "").strip()
            if not std_name:
                continue
            name_map[std_name.lower()] = std_name
            others = str(row.get("other_names", ""))
            for alias in others.split(","):
                alias = alias.strip()
                if alias:
                    name_map[alias.lower()] = std_name
    return name_map

# ==============================
# åç§°é¢„æ¸…ç†
# ==============================
def clean_channel_name(name):
    """å»é™¤æ‹¬å·å†…å®¹ä¸ç‰¹æ®Šæ ‡è®°"""
    name = str(name)
    name = re.sub(r"ï¼ˆ.*?ï¼‰|\(.*?\)|\[.*?\]", "", name)
    return name.strip()

# ==============================
# è‡ªæœ‰æºæ ‡å‡†åŒ–ï¼ˆä¸åšåŒ¹é…ï¼‰
# ==============================
def standardize_my_sum(path):
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–è‡ªæœ‰æº (ä¸åŒ¹é…): {path}")
    df = safe_read_csv(path)
    df.insert(0, "æ ‡å‡†é¢‘é“å", df.iloc[:, 0].astype(str))
    df.insert(1, "åŒ¹é…çŠ¶æ€", ["æœªåŒ¹é…-è·³è¿‡"] * len(df))
    out_path = path.replace(".csv", "_standardized.csv")
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ç”Ÿæˆ: {out_path}")
    return df

# ==============================
# working.csv åŒ¹é…æµç¨‹
# ==============================
def standardize_working(working_path, my_df, name_map):
    print(f"ğŸ“‚ æ­£åœ¨å¤„ç†ç½‘ç»œæºåŒ¹é…: {working_path}")
    df = safe_read_csv(working_path)
    original_names = df.iloc[:, 0].astype(str)

    my_names = my_df["æ ‡å‡†é¢‘é“å"].astype(str).tolist()
    all_network_keys = list(name_map.keys())

    final_names, match_status = [], []

    for name in original_names:
        cleaned_name = clean_channel_name(name)

        # Step 1ï¸âƒ£ ä¸è‡ªæœ‰æºåŒ¹é…
        my_match = process.extractOne(cleaned_name, my_names, score_cutoff=90)
        if my_match:
            std_name = my_match[0]
            score = my_match[1]
            status = f"ä¸è‡ªæœ‰æºåŒ¹é…({score})"
        else:
            # Step 2ï¸âƒ£ ä¸ç½‘ç»œæ•°æ®åº“åŒ¹é…
            net_match = process.extractOne(cleaned_name.lower(), all_network_keys)
            if net_match:
                matched_key, score, _ = net_match
                if score >= 95:
                    std_name = name_map[matched_key]
                    status = f"ç½‘ç»œåŒ¹é…({score})"
                else:
                    std_name = name
                    status = f"ä½ç½®ä¿¡åº¦({score})"
            else:
                std_name = name
                status = "æœªåŒ¹é…"

        final_names.append(std_name)
        match_status.append(status)

    df.insert(0, "æ ‡å‡†é¢‘é“å", final_names)
    df.insert(1, "åŒ¹é…çŠ¶æ€", match_status)

    out_path = working_path.replace(".csv", "_standardized.csv")
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ç”Ÿæˆ: {out_path}")
    return df

# ==============================
# ä¸»æµç¨‹
# ==============================
def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ ‡å‡†åŒ–åŒ¹é…æµç¨‹...\n")
    print("è¯»å–æºæ–‡ä»¶ï¼š")
    print(f"  ğŸ“ {INPUT_MY}")
    print(f"  ğŸ“ {INPUT_WORKING}")
    print(f"  ğŸ“ {INPUT_NETWORK}\n")

    # è‡ªåŠ¨è¯»å–å¹¶è½¬ç 
    my_df = safe_read_csv(INPUT_MY)
    working_df = safe_read_csv(INPUT_WORKING)
    network_df = safe_read_csv(INPUT_NETWORK)

    print(f"ğŸ“¦ å¤„ç†è‡ªæœ‰æº my_sum.csv å…± {len(my_df)} æ¡")
    my_df = standardize_my_sum(INPUT_MY)

    print(f"ğŸŒ åŠ è½½ iptv-org æ•°æ®åº“ä¸­...")
    name_map = load_name_map()
    print(f"ğŸ“š å·²åŠ è½½ {len(name_map)} ä¸ªé¢‘é“æ˜ å°„")

    print(f"ğŸŒ å¤„ç†ç½‘ç»œæº working.csv å…± {len(working_df)} æ¡")
    working_df = standardize_working(INPUT_WORKING, my_df, name_map)

    # ç”Ÿæˆæ€»æ±‡æ€»æ–‡ä»¶
    total_df = pd.concat([my_df, working_df], ignore_index=True)
    total_df.to_csv(OUTPUT_TOTAL, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ç”Ÿæˆæ±‡æ€»æ–‡ä»¶: {OUTPUT_TOTAL}")

    # æå–é¢‘é“åä¸åˆ†ç»„
    if "æ ‡å‡†é¢‘é“å" in total_df.columns and total_df.shape[1] > 5:
        channel_df = total_df[["æ ‡å‡†é¢‘é“å", total_df.columns[5]]]
        channel_df.to_csv(OUTPUT_CHANNEL, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²æå–é¢‘é“æ˜ å°„: {OUTPUT_CHANNEL}")

    print("\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼")

# ==============================
# æ‰§è¡Œå…¥å£
# ==============================
if __name__ == "__main__":
    main()