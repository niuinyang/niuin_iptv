import csv
import os
import pandas as pd
from rapidfuzz import process
import re
import chardet

IPTV_DB_PATH = "./iptv-database"

INPUT_MY = "input/mysource/my_sum.csv"
INPUT_WORKING = "output/working.csv"
OUTPUT_TOTAL = "output/total.csv"
OUTPUT_CHANNEL = "input/channel.csv"

def safe_read_csv(path):
    with open(path, "rb") as f:
        raw = f.read()
    result = chardet.detect(raw)
    enc = result["encoding"]
    if enc is None:
        enc = "utf-8"
    if enc.lower() != "utf-8":
        text = raw.decode(enc, errors="ignore")
        with open(path, "w", encoding="utf-8") as f:
            f.write(text)
    return pd.read_csv(path, encoding="utf-8")

def load_name_map():
    name_map = {}
    path = os.path.join(IPTV_DB_PATH, "data", "channels.csv")
    with open(path, encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            std_name = row["name"].strip()
            name_map[std_name.lower()] = std_name
            others = row.get("other_names", "")
            for alias in others.split(","):
                alias = alias.strip()
                if alias:
                    name_map[alias.lower()] = std_name
    return name_map

def clean_channel_name(name):
    if not isinstance(name, str):
        return ""
    # å»é™¤ï¼ˆï¼‰å’Œã€ã€‘åŠé‡Œé¢å†…å®¹
    name = re.sub(r"[\(\ï¼ˆ][^\)\ï¼‰]*[\)\ï¼‰]", "", name)
    name = re.sub(r"[\[\ã€][^\]\ã€‘]*[\]\ã€‘]", "", name)
    return name.strip()

def get_std_name(name, name_map, threshold=95):
    name_lower = name.lower()
    if name_lower in name_map:
        return name_map[name_lower], 100.0, "ç²¾ç¡®åŒ¹é…"
    choices = list(name_map.keys())
    match, score, _ = process.extractOne(name_lower, choices)
    if score >= threshold:
        return name_map[match], score, "æ¨¡ç³ŠåŒ¹é…"
    else:
        return name, score, "æœªåŒ¹é…"

def standardize_my_sum(my_sum_df):
    my_sum_df['final_name'] = my_sum_df.iloc[:,0].astype(str)
    my_sum_df['match_info'] = "è‡ªæœ‰æº"
    my_sum_df['original_channel_name'] = my_sum_df.iloc[:,0].astype(str)
    return my_sum_df

def standardize_working(working_df, my_sum_df, name_map):
    working_df['original_channel_name'] = working_df.iloc[:, 0].astype(str)
    working_df['clean_name'] = working_df['original_channel_name'].apply(clean_channel_name)
    my_name_dict = dict(zip(my_sum_df.iloc[:,0].str.lower(), my_sum_df['final_name']))

    total = len(working_df)
    final_names = []
    match_infos = []
    matched_count = 0
    unmatched_count = 0

    print(f"ğŸ”„ å¼€å§‹å¯¹ working.csv å…± {total} æ¡è®°å½•è¿›è¡Œæ ‡å‡†åŒ–åŒ¹é…...")

    for idx, (orig_name, clean_name) in enumerate(zip(working_df['original_channel_name'], working_df['clean_name']), 1):
        clean_name_lower = clean_name.lower()
        if clean_name_lower in my_name_dict:
            std_name = my_name_dict[clean_name_lower]
            match_info = "è‡ªæœ‰æºåŒ¹é…"
            matched_count += 1
        else:
            std_name, score, info = get_std_name(clean_name, name_map)
            if score < 95:
                std_name = orig_name
                match_info = "æœªåŒ¹é…"
                unmatched_count += 1
            else:
                match_info = info
                matched_count += 1

        final_names.append(std_name)
        match_infos.append(match_info)

        if idx % 200 == 0 or idx == total:
            print(f"å·²å¤„ç† {idx}/{total} æ¡ï¼Œå·²åŒ¹é… {matched_count} æ¡ï¼ŒæœªåŒ¹é… {unmatched_count} æ¡")

    working_df['final_name'] = final_names
    working_df['match_info'] = match_infos
    return working_df

def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ ‡å‡†åŒ–åŒ¹é…æµç¨‹...")

    my_sum_df = safe_read_csv(INPUT_MY)
    working_df = safe_read_csv(INPUT_WORKING)

    print(f"è¯»å–æºæ–‡ä»¶ï¼š\n  ğŸ“ {INPUT_MY}\n  ğŸ“ {INPUT_WORKING}")

    name_map = load_name_map()
    print(f"âœ… æ•°æ®åº“åŠ è½½å®Œæˆï¼Œæ˜ å°„æ€»æ•°ï¼š{len(name_map)}")

    my_sum_df = standardize_my_sum(my_sum_df)
    working_df = standardize_working(working_df, my_sum_df, name_map)

    def build_total_df(df):
        cols = df.columns.tolist()
        addr = df.iloc[:,1] if len(cols) > 1 else pd.Series([""]*len(df))
        source = df.iloc[:,2] if len(cols) > 2 else pd.Series([""]*len(df))
        check_time = df.iloc[:,3] if len(cols) > 3 else pd.Series([""]*len(df))
        icon = df.iloc[:,4] if len(cols) > 4 else pd.Series([""]*len(df))
        group = df.iloc[:,5] if len(cols) > 5 else pd.Series([""]*len(df))

        if 'original_channel_name' in df.columns:
            original_channel_name = df['original_channel_name']
        else:
            original_channel_name = df.iloc[:,0].astype(str)

        match_info = df['match_info'] if 'match_info' in df.columns else pd.Series(["è‡ªæœ‰æº"]*len(df))

        return pd.DataFrame({
            "é¢‘é“å": df['final_name'],
            "åœ°å€": addr,
            "æ¥æº": source,
            "æ£€æµ‹æ—¶é—´": check_time,
            "å›¾æ ‡": icon,
            "åˆ†ç»„": group,
            "åŒ¹é…ä¿¡æ¯": match_info,
            "åŸå§‹é¢‘é“å": original_channel_name
        })

    my_sum_out = build_total_df(my_sum_df)
    working_out = build_total_df(working_df)

    total_df = pd.concat([my_sum_out, working_out], ignore_index=True)
    total_df.to_csv(OUTPUT_TOTAL, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ç”Ÿæˆåˆå¹¶æ–‡ä»¶: {OUTPUT_TOTAL}")

    # è¾“å‡º channel.csv ä¸¤åˆ—ï¼šfinal_name å’Œ åˆ†ç»„
    channel_list = []
    for df in [my_sum_df, working_df]:
        for _, row in df.iterrows():
            final_name = row['final_name']
            group = ""
            if len(row) > 5:
                group = row.iloc[5] if isinstance(row, pd.Series) else (row[5] if len(row) > 5 else "")
            channel_list.append((final_name, group))
    channel_df = pd.DataFrame(channel_list, columns=["final_name", "åˆ†ç»„"])
    channel_df.drop_duplicates(inplace=True)
    channel_df.to_csv(OUTPUT_CHANNEL, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ç”Ÿæˆé¢‘é“åˆ—è¡¨æ–‡ä»¶: {OUTPUT_CHANNEL}")

if __name__ == "__main__":
    main()