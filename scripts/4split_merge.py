#!/usr/bin/env python3
import csv
import os
import sys

def split_deep_scan(input_path="output/merge_total.csv",
                    chunk_size=1000,
                    output_dir="output/middle/chunk"):
    """
    å°† merge_total.csv æŒ‰ chunk_size è¡Œåˆ†å‰²åˆ° output/middle/chunk ç›®å½•ã€‚
    è¾“å‡ºæ–‡ä»¶å‘½åæ ¼å¼ï¼šchunk(æ€»æ–‡ä»¶æ•°)-1.csv, chunk(æ€»æ–‡ä»¶æ•°)-2.csv ...
    """
    print("ğŸ” å½“å‰å·¥ä½œç›®å½•:", os.getcwd())
    print(f"ğŸ“„ è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")

    # ç¡®è®¤è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        print(f"âŒ æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {input_path}")
        sys.exit(1)

    # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # æ¸…ç†æ—§çš„ chunk æ–‡ä»¶
    print("ğŸ§¹ æ¸…ç†æ—§çš„ chunk æ–‡ä»¶...")
    for f in os.listdir(output_dir):
        if f.endswith(".csv") and f.startswith("chunk"):
            path = os.path.join(output_dir, f)
            os.remove(path)
            print(f"åˆ é™¤æ—§æ–‡ä»¶: {f}")

    # è¯»å– CSV å†…å®¹
    try:
        with open(input_path, newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            headers = reader.fieldnames
            rows = list(reader)
    except UnicodeDecodeError:
        print("âš ï¸ UTF-8 è§£ç å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹ç¼–ç ...")
        import chardet
        with open(input_path, 'rb') as f:
            data = f.read()
            result = chardet.detect(data)
            encoding = result['encoding'] or 'utf-8'
        print(f"ğŸ“˜ æ£€æµ‹åˆ°ç¼–ç : {encoding}")
        text = data.decode(encoding, errors='ignore')
        rows = list(csv.DictReader(text.splitlines()))
        headers = rows[0].keys() if rows else []

    total = len(rows)
    print(f"âœ… è¯»å–åˆ° {total} è¡Œæ•°æ®")

    # è®¡ç®—æ€»å—æ•°
    total_chunks = (total + chunk_size - 1) // chunk_size
    print(f"ğŸ“¦ å°†åˆ†æˆ {total_chunks} ä¸ªæ–‡ä»¶")

    # æŒ‰å—åˆ†å‰²
    for i in range(0, total, chunk_size):
        chunk_rows = rows[i:i + chunk_size]
        chunk_num = i // chunk_size + 1
        chunk_filename = f"chunk{total_chunks}-{chunk_num}.csv"
        chunk_path = os.path.join(output_dir, chunk_filename)

        with open(chunk_path, "w", newline='', encoding='utf-8') as cf:
            writer = csv.DictWriter(cf, fieldnames=headers)
            writer.writeheader()
            writer.writerows(chunk_rows)

        print(f"ğŸ§© å·²å†™å…¥ {chunk_path} ({len(chunk_rows)} è¡Œ)")

    print("âœ… æ‰€æœ‰åˆ†ç‰‡æ–‡ä»¶å†™å…¥å®Œæˆã€‚")


if __name__ == "__main__":
    split_deep_scan()