#!/usr/bin/env python3
# scripts/merge_and_match.py
import csv
import os
import pandas as pd
from rapidfuzz import process
import re
import chardet

IPTV_DB_PATH = "./iptv-database"

INPUT_MY = "input/mysource/my_sum.csv"
INPUT_WORKING = "output/working.csv"
OUTPUT_TOTAL = "output/total.csv"
INPUT_CHANNEL = "input/channel.csv"   # ä½œä¸ºè¾“å…¥çš„channel.csv
OUTPUT_CHANNEL = "input/channel.csv"  # è¦†ç›–å†™å›
MANUAL_MAP_PATH = "input/manual_map.csv"


# -----------------------------
# ğŸ”¹ è‡ªåŠ¨æ£€æµ‹ CSV ç¼–ç 
# -----------------------------
def read_csv_auto_encoding(path):
    with open(path, "rb") as fb:
        raw = fb.read(20000)
        detected_enc = chardet.detect(raw)["encoding"] or "utf-8"
    try:
        df = pd.read_csv(path, encoding=detected_enc)
    except Exception:
        df = pd.read_csv(path, encoding="utf-8-sig")
    return df


# -----------------------------
# ğŸ”¹ è½½å…¥é¢‘é“æ•°æ®åº“
# -----------------------------
def load_channel_database():
    db_channels = []
    for root, _, files in os.walk(IPTV_DB_PATH):
        for f in files:
            if f.endswith(".csv"):
                try:
                    df = read_csv_auto_encoding(os.path.join(root, f))
                    if "name" in df.columns:
                        db_channels.extend(df["name"].dropna().astype(str).tolist())
                except Exception:
                    pass
    return list(set(db_channels))


# -----------------------------
# ğŸ”¹ æ¨¡ç³ŠåŒ¹é…å‡½æ•°
# -----------------------------
def fuzzy_match_channel(name, db_channels, threshold=80):
    if not isinstance(name, str) or not name.strip():
        return None, 0
    result = process.extractOne(name, db_channels, score_cutoff=threshold)
    if result:
        return result[0], result[1]
    return None, 0


# -----------------------------
# ğŸ”¹ å¯¼å‡ºæœªåŒ¹é…é¢‘é“ä»¥äººå·¥è¡¥å…¨ï¼ˆä¿®æ­£ç‰ˆ âœ…ï¼‰
# -----------------------------
def export_unmatched_for_manual(working_df, manual_map_path=MANUAL_MAP_PATH):
    """
    å¯¼å‡ºæœªåŒ¹é…æˆ–ä½åŒ¹é…é¢‘é“ï¼Œç”¨äºäººå·¥è¡¥å…¨æ ‡å‡†åç§°
    è¾“å‡ºåˆ—ï¼šåŸå§‹åç§°, æ ‡å‡†åç§°(ç©º), æ‹ŸåŒ¹é…é¢‘é“
    """
    # ç­›é€‰å‡ºæœªåŒ¹é…æˆ–ä½åŒ¹é…çš„é¢‘é“
    unmatched_df = working_df[working_df['match_info'].str.contains("æœªåŒ¹é…|ä½åŒ¹é…", na=False)]

    # ä» match_info ä¸­æå–â€œæ‹ŸåŒ¹é…é¢‘é“â€
    def extract_candidate(info):
        m = re.search(r"æ‹ŸåŒ¹é…é¢‘é“:([^,ï¼Œ]*)", str(info))
        return m.group(1).strip() if m else ""

    # æ„é€ å¯¼å‡º DataFrameï¼ˆåªä¿ç•™ä¸‰åˆ—ï¼‰
    export_df = pd.DataFrame({
        "åŸå§‹åç§°": unmatched_df['original_channel_name'],
        "æ ‡å‡†åç§°": "",
        "æ‹ŸåŒ¹é…é¢‘é“": unmatched_df['match_info'].apply(extract_candidate)
    }).drop_duplicates(subset=["åŸå§‹åç§°"], keep="first")

    # æ£€æŸ¥ manual_map.csv æ˜¯å¦å­˜åœ¨
    if os.path.exists(manual_map_path):
        existing = pd.read_csv(manual_map_path, encoding="utf-8-sig")
        existing_names = existing['åŸå§‹åç§°'].str.lower().tolist()
    else:
        os.makedirs(os.path.dirname(manual_map_path), exist_ok=True)
        with open(manual_map_path, "w", encoding="utf-8-sig", newline='') as f:
            writer = csv.writer(f)
            writer.writerow(["åŸå§‹åç§°", "æ ‡å‡†åç§°", "æ‹ŸåŒ¹é…é¢‘é“"])
        existing_names = []

    # åªå†™å…¥æ–°çš„æœªåŒ¹é…é¢‘é“
    new_rows = export_df[~export_df['åŸå§‹åç§°'].str.lower().isin(existing_names)]

    if not new_rows.empty:
        new_rows.to_csv(manual_map_path, mode='a', index=False, header=False, encoding="utf-8-sig")
        print(f"ğŸ”” æœ‰ {len(new_rows)} ä¸ªæœªåŒ¹é…æˆ–ä½åŒ¹é…é¢‘é“å†™å…¥åˆ° {manual_map_path}ï¼Œè¯·æ‰‹åŠ¨è¡¥å…¨æ ‡å‡†åç§°ã€‚")
    else:
        print(f"ğŸ”” æ— æ–°å¢æœªåŒ¹é…æˆ–ä½åŒ¹é…é¢‘é“å†™å…¥ {manual_map_path}ã€‚")


# -----------------------------
# ğŸ”¹ ä¸»å¤„ç†é€»è¾‘
# -----------------------------
def main():
    print("ğŸš€ è½½å…¥æ•°æ®ä¸­...")

    df_my = read_csv_auto_encoding(INPUT_MY)
    df_working = read_csv_auto_encoding(INPUT_WORKING)

    db_channels = load_channel_database()
    print(f"ğŸ“š é¢‘é“æ•°æ®åº“åŠ è½½å®Œæˆï¼Œå…± {len(db_channels)} æ¡ã€‚")

    matches = []
    for _, row in df_working.iterrows():
        ch_name = str(row.get("name", "")).strip()
        best_match, score = fuzzy_match_channel(ch_name, db_channels)
        if best_match:
            if score >= 90:
                info = f"é«˜åŒ¹é…: {best_match} ({score:.1f})"
            elif score >= 70:
                info = f"ä½åŒ¹é…;æ‹ŸåŒ¹é…é¢‘é“:{best_match}"
            else:
                info = f"æœªåŒ¹é…"
        else:
            info = "æœªåŒ¹é…"

        matches.append({
            "original_channel_name": ch_name,
            "match_info": info
        })

    df_match = pd.DataFrame(matches)
    df_match.to_csv(OUTPUT_TOTAL, index=False, encoding="utf-8-sig")
    print(f"âœ… åŒ¹é…ç»“æœå·²ä¿å­˜åˆ° {OUTPUT_TOTAL}")

    # å¯¼å‡ºäººå·¥åŒ¹é…æ–‡ä»¶
    export_unmatched_for_manual(df_match)


if __name__ == "__main__":
    main()