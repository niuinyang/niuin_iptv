#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç¼–ç ç‰ˆ IPTV åˆå¹¶è„šæœ¬
æ”¯æŒå¤šè¯­è¨€æ–‡ä»¶ï¼ˆä¸­æ–‡ / è‹±æ–‡ / ä¿„è¯­ / è¥¿è‘¡è¯­ï¼‰
è¾“å‡ºæ–‡ä»¶ UTF-8 æ—  BOMï¼Œå…¼å®¹ Excel / GitHub / Windows / macOS
"""

import os
import re
import csv
import unicodedata
import chardet
import platform

# ==============================
# é…ç½®åŒº
# ==============================
SOURCE_DIR = "input/network/network_sources"  # M3U å’Œ TXT æ–‡ä»¶æ‰€åœ¨ç›®å½•
OUTPUT_DIR = "output"
LOG_DIR = os.path.join(OUTPUT_DIR, "log")
ICON_DIR = "png"  # ä¿ç•™ç›®å½•ï¼Œä¸ä¸‹è½½å›¾æ ‡

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(ICON_DIR, exist_ok=True)

OUTPUT_M3U = os.path.join(OUTPUT_DIR, "merge_total.m3u")
OUTPUT_CSV = os.path.join(OUTPUT_DIR, "merge_total.csv")
SKIPPED_LOG = os.path.join(LOG_DIR, "skipped.log")

# ==============================
# å·¥å…·å‡½æ•°
# ==============================

def safe_open(file_path):
    """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç å¹¶è¿”å›æŒ‰è¡Œåˆ—è¡¨"""
    with open(file_path, 'rb') as f:
        raw = f.read()
        enc = chardet.detect(raw)['encoding'] or 'utf-8'
    try:
        text = raw.decode(enc, errors='ignore')
    except Exception:
        text = raw.decode('utf-8', errors='ignore')
    # æ¸…ç†éšè—å­—ç¬¦
    text = text.replace('\x00', '')
    return text.splitlines()

def normalize_channel_name(name: str) -> str:
    """æ ‡å‡†åŒ–é¢‘é“åï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰"""
    if not name:
        return ""
    name = unicodedata.normalize("NFKC", name)
    name = re.sub(r"[\s\[\]ï¼ˆï¼‰()ã€ã€‘]", "", name)
    name = re.sub(r"[-_\.]", "", name)
    return name.strip().lower()

def get_icon_path(standard_name, tvg_logo_url):
    # ä¸ä¸‹è½½å›¾æ ‡ï¼Œä»…è¿”å› URL
    return tvg_logo_url or ""

def read_m3u_file(file_path: str):
    """è¯»å– M3U æ–‡ä»¶"""
    channels = []
    try:
        lines = safe_open(file_path)
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            if line.startswith("#EXTINF:"):
                info_line = line
                url_line = lines[i + 1].strip() if i + 1 < len(lines) else ""

                # æå–é¢‘é“åä¸ºé€—å·åçš„æ‰€æœ‰å†…å®¹ï¼Œé¿å…å±æ€§å†…é€—å·å¹²æ‰°
                m = re.match(r'#EXTINF:-?\d+\s*(?:.*?),\s*(.*)', info_line)
                if m:
                    display_name = m.group(1).strip()
                else:
                    display_name = "æœªçŸ¥é¢‘é“"

                logo_match = re.search(r'tvg-logo=[\'"]([^\'"]+)[\'"]', info_line)
                tvg_logo_url = logo_match.group(1).strip() if logo_match else ""

                icon_path = get_icon_path(display_name, tvg_logo_url)

                channels.append({
                    "display_name": display_name,
                    "url": url_line,
                    "logo": icon_path
                })
                i += 2
            else:
                i += 1

        print(f"ğŸ“¡ å·²åŠ è½½ {os.path.basename(file_path)}: {len(channels)} æ¡é¢‘é“")
        return channels

    except Exception as e:
        print(f"âš ï¸ è¯»å– {file_path} å¤±è´¥: {e}")
        return []

def read_txt_multi_section_csv(file_path: str):
    """è¯»å–å¤šæ®µæ ‡é¢˜ TXT/CSV æ–‡ä»¶"""
    channels = []
    try:
        lines = safe_open(file_path)
        for line in lines:
            line = line.strip()
            if not line or "#genre#" in line:
                continue
            parts = line.split(",", 1)
            if len(parts) != 2:
                continue
            display_name, url = parts[0].strip(), parts[1].strip()
            if not url.startswith("http"):
                continue
            channels.append({
                "display_name": display_name,
                "url": url,
                "logo": ""
            })
        print(f"ğŸ“¡ å·²åŠ è½½ {os.path.basename(file_path)}: {len(channels)} æ¡é¢‘é“")
        return channels
    except Exception as e:
        print(f"âš ï¸ è¯»å– {file_path} å¤±è´¥: {e}")
        return []

def write_output_files(channels):
    """ç»Ÿä¸€è¾“å‡º UTF-8 æ—  BOM"""
    seen_urls = set()
    valid_channels = []
    skipped_channels = []

    for ch in channels:
        url = ch["url"]
        if not url.startswith("http"):
            skipped_channels.append(ch)
            continue
        if url in seen_urls:
            skipped_channels.append(ch)
            continue
        seen_urls.add(url)
        valid_channels.append(ch)

    print(f"\nâœ… æœ‰æ•ˆé¢‘é“: {len(valid_channels)} æ¡ï¼ˆå»é‡åï¼‰")
    print(f"ğŸš« è·³è¿‡æ— æ•ˆæˆ–é‡å¤: {len(skipped_channels)} æ¡")

    # å†™ M3Uï¼ˆUTF-8 æ—  BOMï¼‰
    with open(OUTPUT_M3U, "w", encoding="utf-8", newline="\n") as f:
        f.write("#EXTM3U\n")
        for ch in valid_channels:
            display_name = ch["display_name"]
            url = ch["url"]
            f.write(f'#EXTINF:-1,{display_name}\n{url}\n')

    # å†™ CSVï¼ˆUTF-8 æ—  BOMï¼‰
    with open(OUTPUT_CSV, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["é¢‘é“å", "åœ°å€", "æ¥æº", "å›¾æ ‡"])
        for ch in valid_channels:
            writer.writerow([ch["display_name"], ch["url"], "ç½‘ç»œæº", ch.get("logo", "")])

    # å†™è·³è¿‡æ—¥å¿—ï¼ˆUTF-8 æ—  BOMï¼‰
    with open(SKIPPED_LOG, "w", encoding="utf-8") as f:
        for ch in skipped_channels:
            f.write(f"{ch['display_name']},{ch['url']}\n")

    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_M3U} å’Œ {OUTPUT_CSV}")
    print(f"ğŸ“ è·³è¿‡æ—¥å¿—ï¼š{SKIPPED_LOG}")

def merge_all_sources():
    """åˆå¹¶ç›®å½•å†…æ‰€æœ‰ M3U / TXT æº"""
    all_channels = []
    if not os.path.exists(SOURCE_DIR):
        print(f"âš ï¸ æºç›®å½•ä¸å­˜åœ¨: {SOURCE_DIR}")
        return []

    print(f"ğŸ“‚ æ‰«æç›®å½•: {SOURCE_DIR}")
    for file in os.listdir(SOURCE_DIR):
        file_path = os.path.join(SOURCE_DIR, file)
        if file.endswith(".m3u"):
            chs = read_m3u_file(file_path)
        elif file.endswith(".txt"):
            chs = read_txt_multi_section_csv(file_path)
        else:
            continue
        all_channels.extend(chs)

    print(f"\nğŸ“Š åˆå¹¶æ‰€æœ‰é¢‘é“ï¼Œå…± {len(all_channels)} æ¡")
    return all_channels

if __name__ == "__main__":
    print(f"ğŸ”§ å½“å‰ç³»ç»Ÿ: {platform.system()}ï¼Œè¾“å‡ºç»Ÿä¸€ä¸º UTF-8 æ—  BOM")
    channels = merge_all_sources()
    if channels:
        write_output_files(channels)
    else:
        print("âš ï¸ æ²¡æœ‰è¯»å–åˆ°ä»»ä½•é¢‘é“")