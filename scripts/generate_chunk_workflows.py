#!/usr/bin/env python3
# scripts/generate_chunk_workflows.py
import os
import re
import argparse
import json
import subprocess
import time

WORKFLOW_DIR = ".github/workflows"
CHUNK_DIR = "output/chunk"
CACHE_FILE = "output/cache_workflow.json"

os.makedirs(WORKFLOW_DIR, exist_ok=True)
os.makedirs("output", exist_ok=True)

TEMPLATE = """name: Deep Validation Chunk {n}

on:
  schedule:
    - cron: '{cron_min} {cron_hour} * * *'  # è§¦å‘æ—¶é—´ï¼ŒUTCæ—¶é—´
  workflow_dispatch:

permissions:
  contents: write

jobs:
  deep_validate_chunk_{n}:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install ffmpeg
        run: sudo apt-get update && sudo apt-get install -y ffmpeg

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run deep validation for chunk {n}
        run: |
          python scripts/4.3final_scan.py --input {chunk_file} --chunk_id {n} --cache_dir output/cache
"""

def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except json.JSONDecodeError:
            return {}
    return {}

def save_cache(cache):
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(cache, f, indent=2, ensure_ascii=False)

def generate_workflows():
    cache = load_cache()

    # ç»Ÿè®¡æ‰€æœ‰ chunk æ–‡ä»¶ï¼Œæ’åº
    chunk_files = []
    for filename in os.listdir(CHUNK_DIR):
        match = re.match(r"chunk_(\d+)\.csv$", filename)
        if not match:
            print(f"è·³è¿‡ä¸åŒ¹é…çš„æ–‡ä»¶: {filename}")
            continue
        chunk_files.append((int(match.group(1)), filename))
    chunk_files.sort(key=lambda x: x[0])

    # è®¡ç®—è§¦å‘æ—¶é—´ï¼Œèµ·ç‚¹ UTC 19:30ï¼Œå¯¹åº”ä¸œå…«åŒºå‡Œæ™¨3:30ï¼Œé—´éš”10åˆ†é’Ÿ
    start_hour = 19
    start_minute = 30
    interval_min = 10

    for idx, (n_int, filename) in enumerate(chunk_files):
        n = str(n_int)
        workflow_filename = f"deep_chunk_{n}.yml"
        workflow_path = os.path.join(WORKFLOW_DIR, workflow_filename)
        chunk_file_path = os.path.join(CHUNK_DIR, filename)

        # è®¡ç®—cronæ—¶é—´
        total_minutes = start_minute + idx * interval_min
        cron_hour = start_hour + total_minutes // 60
        cron_min = total_minutes % 60
        if cron_hour >= 24:
            cron_hour = cron_hour % 24

        cache_key = f"chunk_{n}"
        if cache.get(cache_key) == workflow_filename and os.path.exists(workflow_path):
            print(f"å·²å­˜åœ¨ä¸”ç¼“å­˜ä¸€è‡´: {workflow_filename} è§¦å‘æ—¶é—´: {cron_min} {cron_hour} * * *")
            continue

        with open(workflow_path, "w", encoding="utf-8") as wf:
            wf.write(TEMPLATE.format(n=n, chunk_file=chunk_file_path, cron_hour=cron_hour, cron_min=cron_min))
        cache[cache_key] = workflow_filename
        print(f"âœ… å·²ç”Ÿæˆ workflow: {workflow_filename} è§¦å‘æ—¶é—´: {cron_min} {cron_hour} * * *")

    save_cache(cache)

def git_commit_push(max_retries=3, wait_seconds=5):
    print("\nğŸŒ€ æäº¤ç”Ÿæˆçš„ workflow åˆ° GitHub...")

    try:
        # å…ˆå¼ºåˆ¶æ¸…ç†æœ¬åœ°æ”¹åŠ¨ï¼Œç¡®ä¿pullä¸æŠ¥é”™
        subprocess.run(["git", "reset", "--hard"], check=True)
        subprocess.run(["git", "clean", "-fd"], check=True)

        subprocess.run(["git", "pull", "--rebase"], check=True)

        subprocess.run(["git", "add", ".github/workflows"], check=True)
        subprocess.run(["git", "add", "output/cache"], check=True)  # æ·»åŠ ç¼“å­˜ç›®å½•
        subprocess.run(["git", "commit", "-m", "ci: auto-generate deep validation workflows"], check=False)
    except subprocess.CalledProcessError as e:
        print("âš ï¸ Git é¢„å¤„ç†å¤±è´¥:", e)
        return

    for attempt in range(1, max_retries + 1):
        try:
            subprocess.run(["git", "push"], check=True)
            print("âœ… å·²æˆåŠŸæ¨é€åˆ°è¿œç¨‹ä»“åº“")
            break
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸ ç¬¬ {attempt} æ¬¡æ¨é€å¤±è´¥:", e)
            if attempt < max_retries:
                print(f"â³ ç­‰å¾… {wait_seconds} ç§’åé‡è¯•æ¨é€...")
                try:
                    subprocess.run(["git", "pull", "--rebase"], check=True)
                except subprocess.CalledProcessError as pull_err:
                    print("âš ï¸ è‡ªåŠ¨æ‹‰å–è¿œç¨‹æœ€æ–°å¤±è´¥ï¼Œè·³è¿‡é‡è¯•:", pull_err)
                    break
                time.sleep(wait_seconds)
            else:
                print("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ¨é€å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥å†²çªã€‚")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--no-push", action="store_true", help="ä»…ç”Ÿæˆï¼Œä¸æ‰§è¡Œ git push")
    args = parser.parse_args()

    generate_workflows()

    if not args.no_push:
        git_commit_push()