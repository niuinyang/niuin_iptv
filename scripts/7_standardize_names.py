#!/usr/bin/env python3
# standardize_iptv.py (CSV ç‰ˆæœ¬ï¼Œæ—  Excel)

import os
import re
import csv
import sys
import time
import chardet
import pandas as pd
from opencc import OpenCC
from rapidfuzz import fuzz, process
from tqdm import tqdm

# =============================
# é…ç½®è·¯å¾„ï¼Œå·²ç»å…¨éƒ¨ç»Ÿä¸€ä¸º CSV
# =============================
MY_SUM_PATH = "output/middle/merge/mysource_total.csv"
WORKING_PATH = "output/middle/working.csv"

CHANNEL_DATA_PATH = "input/channel_data.csv"        # CSV è¾“å‡ºè·¯å¾„
NETWORK_CHANNELS_PATH = "input/iptv-org/database/data/channels.csv"

OUTPUT_TOTAL_FINAL = "output/total_final.csv"
OUTPUT_CHANNEL_DATA = CHANNEL_DATA_PATH

cc = OpenCC('t2s')


# =============================
# è‡ªåŠ¨ç¼–ç è¯†åˆ«è¯» CSV
# =============================
def read_csv_auto_encoding(filepath):
    with open(filepath, 'rb') as f:
        raw = f.read(10000)
        result = chardet.detect(raw)
        encoding = result['encoding'] or 'utf-8'
    return pd.read_csv(filepath, encoding=encoding)


def mechanical_standardize(name: str) -> str:
    if not isinstance(name, str):
        return ""
    s = name.strip()
    s = cc.convert(s)
    s = s.lower()
    s = re.sub(r"\ï¼ˆ.*?\ï¼‰", "", s)
    s = re.sub(r"\(.*?\)", "", s)
    s = re.sub(r"\[.*?\]", "", s)
    s = re.sub(r"\ã€.*?\ã€‘", "", s)
    s = re.sub(r"\s+", "", s)
    s = re.sub(r"[^a-z0-9\u4e00-\u9fa5\+\ï¼]", "", s)
    return s


def clean_network_std_name(name: str) -> str:
    if not isinstance(name, str):
        return ""
    name = name.strip()
    name = re.sub(r"\s+", " ", name)
    name = ' '.join([
        w.capitalize() if re.match(r'[a-zA-Z]+$', w) else w
        for w in name.split(" ")
    ])
    return name


# =============================
#  ä¸»ç¨‹åº
# =============================
def main():
    print("å¼€å§‹è¯»å–æ–‡ä»¶...")

    # è¯»å– my_sum, working
    my_sum = read_csv_auto_encoding(MY_SUM_PATH)
    working = read_csv_auto_encoding(WORKING_PATH)

    # =============================
    #  CSVï¼šå¦‚æœä¸å­˜åœ¨ channel_dataï¼Œåˆ™åˆ›å»º
    # =============================
    if not os.path.exists(CHANNEL_DATA_PATH):
        pd.DataFrame(columns=["åŸå§‹å", "æ ‡å‡†å", "æ‹ŸåŒ¹é…é¢‘é“å", "åˆ†ç»„"]).to_csv(
            CHANNEL_DATA_PATH, index=False, encoding="utf-8-sig"
        )

    channel_data = read_csv_auto_encoding(CHANNEL_DATA_PATH)

    # æ–°å¢é»˜è®¤åˆ—ï¼šæ¥æºã€è¾“å‡ºé¡ºåºã€æ˜¯å¦å·²ç»´æŠ¤
    # æ¥æºåˆ—å¡«å……é€»è¾‘ï¼šä» my_sum å’Œ working å–å¯¹åº”é¢‘é“åçš„æ¥æºå­—æ®µ
    source_dict = {}
    for df in [my_sum, working]:
        for idx, row in df.iterrows():
            orig_name = row.get("é¢‘é“å", "")
            src = row.get("æ¥æº", "")
            if orig_name and src:
                if orig_name not in source_dict:
                    source_dict[orig_name] = src

    # èµ‹é»˜è®¤å€¼å’Œæ˜ å°„
    if "æ¥æº" not in channel_data.columns:
        channel_data["æ¥æº"] = channel_data["åŸå§‹å"].map(source_dict).fillna("")
    else:
        # å¦‚æœå·²å­˜åœ¨æ¥æºåˆ—ï¼Œæ›´æ–°æ˜ å°„ä½†ä¿ç•™å·²æœ‰éç©ºå€¼
        channel_data["æ¥æº"] = channel_data.apply(
            lambda row: source_dict.get(row["åŸå§‹å"], row["æ¥æº"]) if not row["æ¥æº"] else row["æ¥æº"],
            axis=1
        )

    if "è¾“å‡ºé¡ºåº" not in channel_data.columns:
        channel_data["è¾“å‡ºé¡ºåº"] = "æœªæ’åº"

    if "æ˜¯å¦å·²ç»´æŠ¤" not in channel_data.columns:
        channel_data["æ˜¯å¦å·²ç»´æŠ¤"] = "å¦"

    # =============================
    # ç½‘ç»œé¢‘é“åº“
    # =============================
    network_channels_df = read_csv_auto_encoding(NETWORK_CHANNELS_PATH)

    if "channel" in network_channels_df.columns:
        network_col = "channel"
    elif "name" in network_channels_df.columns:
        network_col = "name"
    else:
        print("ç½‘ç»œæ•°æ®åº“æ— é¢‘é“ååˆ—ï¼")
        sys.exit(1)

    network_channels_df = network_channels_df.dropna(subset=[network_col])
    network_channels_df["std_key"] = network_channels_df[network_col].apply(mechanical_standardize)
    network_channels = dict(zip(network_channels_df["std_key"], network_channels_df[network_col]))

    # =============================
    # ç»Ÿä¸€å­—æ®µ
    # =============================
    for df in [my_sum, working]:
        for col in ["è§†é¢‘ç¼–ç ", "åˆ†è¾¨ç‡", "å¸§ç‡", "éŸ³é¢‘", "ç›¸ä¼¼åº¦"]:
            if col not in df.columns:
                df[col] = ""

    total_before = pd.concat([my_sum, working], ignore_index=True, sort=False)

    required_cols = ["é¢‘é“å", "åœ°å€", "æ¥æº", "å›¾æ ‡", "æ£€æµ‹æ—¶é—´",
                     "åˆ†ç»„", "è§†é¢‘ç¼–ç ", "åˆ†è¾¨ç‡", "å¸§ç‡", "éŸ³é¢‘", "ç›¸ä¼¼åº¦"]

    for col in required_cols:
        if col not in total_before.columns:
            total_before[col] = ""

    total_before["std_key"] = total_before["é¢‘é“å"].apply(mechanical_standardize)

    # channel_data æ ‡å‡†åŒ– key
    channel_data["æ ‡å‡†å_std_key"] = channel_data["æ ‡å‡†å"].apply(mechanical_standardize)
    channel_data["åŸå§‹å_std_key"] = channel_data["åŸå§‹å"].apply(mechanical_standardize)

    existing_orig_names = set(channel_data["åŸå§‹å"].fillna("").unique())

    std_name_dict = dict(zip(channel_data["æ ‡å‡†å_std_key"], channel_data["æ ‡å‡†å"]))
    std_key_to_pending = dict(zip(channel_data["æ ‡å‡†å_std_key"], channel_data["æ‹ŸåŒ¹é…é¢‘é“å"]))

    # åŒ¹é…ç»“æœ
    matched_standard_names = []
    matched_match_info = []
    matched_match_score = []

    precise_match_count = 0
    fuzzy_match_count = 0

    def add_channel_data_if_not_exists(orig_name, std_name, group_label):
        nonlocal channel_data, existing_orig_names
        if orig_name not in existing_orig_names:
            new_row = {
                "åŸå§‹å": orig_name,
                "æ ‡å‡†å": std_name,
                "æ‹ŸåŒ¹é…é¢‘é“å": std_name,
                "åˆ†ç»„": group_label,
                "æ¥æº": source_dict.get(orig_name, ""),
                "è¾“å‡ºé¡ºåº": "æœªæ’åº",
                "æ˜¯å¦å·²ç»´æŠ¤": "å¦"
            }
            channel_data = pd.concat(
                [channel_data, pd.DataFrame([new_row])],
                ignore_index=True
            )
            existing_orig_names.add(orig_name)

    # =============================
    #    é€æ¡åŒ¹é…
    # =============================
    print("å¼€å§‹åŒ¹é…æ ‡å‡†åŒ–é¢‘é“å...")

    total_len = len(total_before)
    batch_size = 50
    last_print_time = time.time()

    for start_idx in tqdm(range(0, total_len, batch_size), desc="åŒ¹é…è¿›åº¦"):
        end_idx = min(start_idx + batch_size, total_len)
        batch = total_before.iloc[start_idx:end_idx]

        for idx, row in batch.iterrows():
            original_name = row["é¢‘é“å"]
            key = row["std_key"]

            matched_name = None
            match_info = "æœªåŒ¹é…"
            match_score = 0.0

            # â€”â€”ç²¾å‡†åŒ¹é…ï¼šåŸå§‹åä¸” æ˜¯å¦å·²ç»´æŠ¤ == "æ˜¯" â€”â€” ä¿®æ”¹ç‚¹
            if original_name in existing_orig_names:
                matched_std_name = channel_data.loc[
                    channel_data["åŸå§‹å"] == original_name, "æ ‡å‡†å"
                ].values
                maintained_val = channel_data.loc[
                    channel_data["åŸå§‹å"] == original_name, "æ˜¯å¦å·²ç»´æŠ¤"
                ].values

                if len(matched_std_name) > 0 and len(maintained_val) > 0:
                    mv = maintained_val[0]
                    if isinstance(mv, str) and mv.strip() == "æ˜¯":
                        matched_name = matched_std_name[0]
                        match_info = "ç²¾å‡†åŒ¹é…"
                        match_score = 100.0
                        precise_match_count += 1
                    else:
                        matched_name = None
                else:
                    matched_name = None

            # â€”â€”æ¨¡ç³ŠåŒ¹é…â€”â€”
            if matched_name is None:
                choices = list(network_channels.keys())
                matches = process.extract(key, choices, scorer=fuzz.ratio, limit=1)

                if matches:
                    best_key, score, _ = matches[0]
                    if score > 90:
                        matched_name = clean_network_std_name(network_channels[best_key])
                        match_info = "æ¨¡ç³ŠåŒ¹é…ï¼ˆ>90%ï¼‰"
                        match_score = float(score)
                        fuzzy_match_count += 1
                        add_channel_data_if_not_exists(original_name, matched_name, "å¾…ç¡®è®¤åˆ†ç»„")
                    else:
                        matched_name = original_name
                        add_channel_data_if_not_exists(original_name, matched_name, "å¾…æ ‡å‡†åŒ–")
                else:
                    matched_name = original_name
                    add_channel_data_if_not_exists(original_name, matched_name, "å¾…æ ‡å‡†åŒ–")

            matched_standard_names.append(matched_name)
            matched_match_info.append(match_info)
            matched_match_score.append(match_score)

        if time.time() - last_print_time >= 5:
            print(f"å·²å¤„ç† {end_idx}/{total_len} æ¡ï¼Œç²¾å‡† {precise_match_count}ï¼Œæ¨¡ç³Š {fuzzy_match_count}")
            last_print_time = time.time()

    # æ›´æ–°æ•°æ®
    total_before["é¢‘é“å"] = matched_standard_names
    total_before["åŒ¹é…ä¿¡æ¯"] = matched_match_info
    total_before["åŒ¹é…å€¼"] = matched_match_score

    # åˆ†ç»„
    std_name_to_group = dict(zip(channel_data["æ ‡å‡†å"], channel_data["åˆ†ç»„"]))
    total_before["åˆ†ç»„"] = total_before["é¢‘é“å"].apply(lambda x: std_name_to_group.get(x, "æœªåˆ†ç±»"))

    # å»é‡
    channel_data = channel_data.drop_duplicates(subset=["åŸå§‹å"], keep='first')

    print("ä¿å­˜è¾“å‡ºæ–‡ä»¶...")

    # ä¿å­˜ total_final.csv
    total_before.to_csv(
        OUTPUT_TOTAL_FINAL, index=False, encoding="utf-8-sig",
        columns=[
            "é¢‘é“å", "åœ°å€", "æ¥æº", "å›¾æ ‡", "æ£€æµ‹æ—¶é—´", "åˆ†ç»„",
            "è§†é¢‘ç¼–ç ", "åˆ†è¾¨ç‡", "å¸§ç‡", "éŸ³é¢‘", "ç›¸ä¼¼åº¦", "åŒ¹é…ä¿¡æ¯", "åŒ¹é…å€¼"
        ]
    )

    # ä¿å­˜ channel_data.csvï¼Œæ–°å¢ä¸‰åˆ—
    channel_data.to_csv(
        OUTPUT_CHANNEL_DATA, index=False, encoding="utf-8-sig",
        columns=["åŸå§‹å", "æ ‡å‡†å", "æ‹ŸåŒ¹é…é¢‘é“å", "åˆ†ç»„", "æ¥æº", "è¾“å‡ºé¡ºåº", "æ˜¯å¦å·²ç»´æŠ¤"]
    )

    print("ğŸ‰ CSV æ ‡å‡†åŒ–å¤„ç†å®Œæˆï¼")


if __name__ == "__main__":
    main()
