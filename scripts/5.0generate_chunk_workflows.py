#!/usr/bin/env python3
# scripts/5.0generate_chunk_workflows.py
import os
import re
import json

WORKFLOW_DIR = ".github/workflows"
CHUNK_DIR = "output/middle/chunk"
CACHE_FILE = "output/cache_workflow.json"

os.makedirs(WORKFLOW_DIR, exist_ok=True)
os.makedirs("output/cache", exist_ok=True)

# æ”¶é›†æ‰€æœ‰ chunk æ–‡ä»¶çš„æ—¶é—´ç‚¹ IDï¼Œæ¯”å¦‚ chunk-0811.csv æå– 0811
chunk_files = sorted([f for f in os.listdir(CHUNK_DIR) if re.match(r"chunk-?\d+\.csv", f)])
chunk_ids = []
for f in chunk_files:
    # å»æ‰ chunk- å’Œ .csvï¼Œä¿ç•™çº¯æ•°å­—/å­—ç¬¦éƒ¨åˆ†ä½œä¸ºæ—¶é—´ç‚¹ID
    m = re.match(r"chunk-?(\d+)\.csv", f)
    if m:
        chunk_ids.append(m.group(1))

# ç”¨é€—å·è¿æ¥æ‰€æœ‰ chunk id å­—ç¬¦ä¸²ï¼Œä¼ ç»™ final_scan
chunk_ids_str = ",".join(chunk_ids)

# ğŸ§© æ¨¡æ¿ï¼ˆæ”¹ä¸ºç›‘å¬ 2pre-process.yml å®Œæˆï¼Œå–æ¶ˆ scheduleï¼‰
TEMPLATE = f"""name: Scan_all_chunks

on:
  workflow_run:
    workflows: ["2é¢„å¤„ç†ğŸš€ IPTVå…¨æµç¨‹ï¼ˆä¸‹è½½â†’åˆå¹¶â†’åˆ†å‰²â†’ç”Ÿæˆï¼‰"]
    types:
      - completed
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scan_all:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install ffmpeg
        run: sudo apt-get update && sudo apt-get install -y ffmpeg

      - name: Install dependencies
        run: pip install -r requirements.txt

      # ä¾æ—§é’ˆå¯¹å•ä¸ª chunk æ–‡ä»¶æ‰§è¡Œ fast_scan å’Œ deep_scanï¼Œå•ç‹¬å¤„ç†æ¯ä¸ª chunk æ–‡ä»¶
"""

# è¿½åŠ æ¯ä¸ª chunk çš„ fast_scan å’Œ deep_scan æ­¥éª¤ï¼ŒåŒæ—¶æœ€åç»Ÿä¸€åšä¸€æ¬¡ final_scan å¤š chunk_ids æ‰«æ
for chunk_id in chunk_ids:
    TEMPLATE += f"""
      - name: Run fast scan for {chunk_id}
        run: |
          mkdir -p output/middle/fast/ok output/middle/fast/not
          python scripts/5.1fast_scan.py \\
            --input output/middle/chunk/chunk-{chunk_id}.csv \\
            --output output/middle/fast/ok/fast_{chunk_id}.csv \\
            --invalid output/middle/fast/not/fast_{chunk_id}-invalid.csv
            
      - name: Run deep scan for {chunk_id}
        run: |
          mkdir -p output/middle/deep/ok output/middle/deep/not
          python scripts/5.2deep_scan.py \\
            --input output/middle/fast/ok/fast_{chunk_id}.csv \\
            --output output/middle/deep/ok/deep_{chunk_id}.csv \\
            --invalid output/middle/deep/not/deep_{chunk_id}-invalid.csv
"""

# æœ€åä¸€æ¬¡æ€§è¿è¡Œ final_scanï¼Œä¼ å…¥æ‰€æœ‰ chunk_ids
TEMPLATE += f"""
      - name: Run final scan for all chunks
        run: |
          mkdir -p output/middle/final/ok output/middle/final/not
          python scripts/5.3final_scan.py \\
            --input output/middle/deep/ok/deep_{{chunk_id}}.csv \\
            --output output/middle/final/ok/final_all.csv \\
            --invalid output/middle/final/not/final_all-invalid.csv \\
            --chunk_ids {chunk_ids_str} \\
            --cache_dir output/cache \\
            --threshold 0.95 \\
            --concurrency 6 \\
            --timeout 20

      - name: Commit and Push Outputs
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # æ·»åŠ æ‰€æœ‰æ‰«æé˜¶æ®µç”Ÿæˆçš„æ–‡ä»¶ï¼Œæ’é™¤ç¼“å­˜æ–‡ä»¶å¤¹
          git add output/middle/fast \\
                  output/middle/deep \\
                  output/middle/final

          if git diff --cached --quiet; then
            echo "No output updates."
            exit 0
          fi

          git commit -m "Update scan outputs for all chunks [skip ci]"

          MAX_RETRIES=5
          COUNT=1

          until git push --quiet; do
            echo "Push failed (attempt $COUNT/$MAX_RETRIES), retrying..."
            git stash push -m "auto-stash" || true
            git pull --rebase --quiet || true
            git stash pop || true
            COUNT=$((COUNT+1))
            if [ $COUNT -gt $MAX_RETRIES ]; then
              echo "ğŸ”¥ Push failed after $MAX_RETRIES attempts."
              exit 1
            fi
            sleep 2
          done

          echo "Push outputs succeeded."
"""

# å†™å…¥ workflow æ–‡ä»¶
workflow_filename = "scan_all_chunks.yml"
workflow_path = os.path.join(WORKFLOW_DIR, workflow_filename)

with open(workflow_path, "w", encoding="utf-8") as f:
    f.write(TEMPLATE)

print(f"âœ… å·²ç”Ÿæˆ workflow: {workflow_filename}")

# å†™å…¥ç¼“å­˜æ–‡ä»¶ï¼ˆchunk id æ˜ å°„ï¼‰
cache_data = {chunk_id: {"file": workflow_filename} for chunk_id in chunk_ids}

with open(CACHE_FILE, "w", encoding="utf-8") as f:
    json.dump(cache_data, f, indent=2, ensure_ascii=False)

print("\nğŸŒ€ æäº¤ç”Ÿæˆçš„ workflow å’Œç¼“å­˜æ–‡ä»¶åˆ° GitHub...\n")
print("âœ… ç”Ÿæˆå®Œæ¯•ï¼Œè„šæœ¬ç»“æŸã€‚")