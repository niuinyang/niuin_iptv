#!/usr/bin/env python3
# scripts/generate_chunk_workflows.py
import os
import re
import json
import time
from datetime import datetime, timedelta
import subprocess

WORKFLOW_DIR = ".github/workflows"
CHUNK_DIR = "output/middle/chunk"
CACHE_FILE = "output/cache_workflow.json"

os.makedirs(WORKFLOW_DIR, exist_ok=True)
os.makedirs("output/cache", exist_ok=True)

# ğŸ§© æ¨¡æ¿ï¼ˆä¿®æ­£ç‰ˆï¼Œæ»¡è¶³éœ€æ±‚ï¼‰
TEMPLATE = """name: Scan_{n}

on:
  schedule:
    - cron: '{cron}'  # æ¯å¤© UTC {utc_hour}:{utc_min:02d} è§¦å‘
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scan_{n}:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install ffmpeg
        run: sudo apt-get update && sudo apt-get install -y ffmpeg

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run fast scan for {n}
        run: |
          mkdir -p output/middle/fast
          mkdir -p output/middle/fast/ok
          mkdir -p output/middle/fast/not
          python scripts/5.1fast_scan.py \
            --input output/middle/chunk/{n}.csv \
            --output output/middle/fast/ok/fast_{n}.csv \
            --invalid output/middle/fast/not/fast_{n}-invalid.csv
            
      - name: Run deep scan for {n}
        run: |
          mkdir -p output/middle/deep
          mkdir -p output/middle/deep/ok
          mkdir -p output/middle/deep/not
          python scripts/5.2deep_scan.py \
            --input output/middle/fast/ok/fast_{n}.csv \
            --output output/middle/deep/ok/deep_{n}.csv \
            --invalid output/middle/deep/not/deep_{n}-invalid.csv

      - name: Run final scan for {n}
        run: |
          mkdir -p output/middle/final
          mkdir -p output/middle/final/ok
          mkdir -p output/middle/final/not
          python scripts/5.3final_scan.py \
            --input output/middle/deep/ok/deep_{n}.csv \
            --output output/middle/final/ok/final_{n}.csv \
            --invalid output/middle/final/not/final_{n}-invalid.csv \
            --chunk_id {n} \
            --cache_dir output/cache

      - name: Commit and push changes
        env:
          GITHUB_TOKEN: ${{{{ secrets.GITHUB_TOKEN }}}}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add output/middle/fast/ output/middle/deep/ output/middle/final/ output/cache/chunk/ || echo "No files to add"
          git commit -m "ci: add scan results and cache for {n}" || echo "No changes to commit"

          # ğŸ”¹ è®¾ç½®è¿œç¨‹å¹¶å¸¦å®‰å…¨æ¨é€é‡è¯•æœºåˆ¶
          git remote set-url origin https://x-access-token:${{GITHUB_TOKEN}}@github.com/niuinyang/niuin_iptv.git

          for i in 1 2 3; do
            echo "æ¨é€å°è¯•ç¬¬ $i æ¬¡"
            if git push origin HEAD:main; then
              echo "æ¨é€æˆåŠŸ âœ…"
              break
            else
              echo "æ¨é€å¤±è´¥ï¼Œå°è¯•æ‹‰å–è¿œç¨‹åˆå¹¶ ğŸ”„"
              git stash push -m "ci: stash before pull"
              if git pull --rebase origin main; then
                echo "æ‹‰å–æˆåŠŸï¼Œå‡†å¤‡é‡è¯•æ¨é€"
                git stash pop || echo "æ—  stash å¯å¼¹å‡º"
              else
                echo "æ‹‰å–å¤±è´¥ï¼Œç­‰å¾… 30 ç§’åé‡è¯•"
                git rebase --abort || true
                git stash pop || echo "æ—  stash å¯å¼¹å‡º"
                sleep 30
              fi
            fi
          done
"""

# ğŸ§¹ æ¸…ç†æ—§ workflow æ–‡ä»¶
print("ğŸ§¹ æ¸…ç†æ—§çš„ workflow æ–‡ä»¶...")
for f in os.listdir(WORKFLOW_DIR):
    if re.match(r"scan_chunk_.+\.yml", f):
        os.remove(os.path.join(WORKFLOW_DIR, f))

if os.path.exists(CACHE_FILE):
    os.remove(CACHE_FILE)

# ğŸ•’ æŒ‰æ—¶é—´é—´éš”åˆ†é… cron
start_hour = 19  # UTC åŸºå‡†å°æ—¶
start_minute = 30
interval = 5  # æ¯ä¸ª chunk ç›¸éš” 5 åˆ†é’Ÿ
chunks = sorted([f for f in os.listdir(CHUNK_DIR) if re.match(r"chunk\d+-\d+\.csv", f)])
total_chunks = len(chunks)

cache_data = {}

for i, chunk_file in enumerate(chunks, start=1):
    utc_hour = start_hour + ((start_minute + (i - 1) * interval) // 60)
    utc_min = (start_minute + (i - 1) * interval) % 60
    if utc_hour >= 24:
        utc_hour -= 24
    cron = f"{utc_min} {utc_hour} * * *"

    # ä»æ–‡ä»¶åä¸­æå– chunk idï¼ˆå»æ‰ .csvï¼‰
    chunk_id = os.path.splitext(chunk_file)[0]

    workflow_filename = f"scan_{chunk_id}.yml"
    workflow_path = os.path.join(WORKFLOW_DIR, workflow_filename)

    with open(workflow_path, "w", encoding="utf-8") as f:
        f.write(TEMPLATE.format(n=chunk_id, cron=cron, utc_hour=utc_hour, utc_min=utc_min))

    print(f"âœ… å·²ç”Ÿæˆ workflow: {workflow_filename} è§¦å‘æ—¶é—´: {cron}")
    cache_data[chunk_id] = {"cron": cron, "file": workflow_filename}

# å†™å…¥ç¼“å­˜æ–‡ä»¶
with open(CACHE_FILE, "w", encoding="utf-8") as f:
    json.dump(cache_data, f, indent=2, ensure_ascii=False)

print("\nğŸŒ€ æäº¤ç”Ÿæˆçš„ workflow å’Œç¼“å­˜æ–‡ä»¶åˆ° GitHub...\n")

# ğŸ§  è‡ªåŠ¨æäº¤å¹¶æ¨é€
subprocess.run(["git", "add", "-A"], check=False)
subprocess.run(["git", "status"], check=False)
commit_msg = "ci: auto-generate scan chunk workflows"
result = subprocess.run(["git", "commit", "-m", commit_msg], text=True)
if result.returncode == 0:
    print("âœ… å·²æäº¤æ›´æ”¹ï¼Œå‡†å¤‡æ¨é€...")
else:
    print("â„¹ï¸ æ— æ›´æ”¹ï¼Œè·³è¿‡æäº¤")

# å¤šæ¬¡æ¨é€é‡è¯•ï¼ˆé˜²æ­¢å¶å‘å†²çªï¼‰
for attempt in range(1, 4):
    print(f"å°è¯•æ¨é€ï¼Œç¬¬ {attempt} æ¬¡...")
    code = subprocess.run(["git", "push"], text=True).returncode
    if code == 0:
        print("ğŸš€ æ¨é€æˆåŠŸ")
        break
    else:
        print("âš ï¸ æ¨é€å¤±è´¥ï¼Œç­‰å¾… 30 ç§’åé‡è¯•...")
        time.sleep(30)
